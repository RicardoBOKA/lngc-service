# Extensions et Am√©liorations - Guide Complet

## üìã Table des mati√®res

1. [Am√©liorations prioritaires](#am√©liorations-prioritaires)
2. [S√©paration des prompts](#s√©paration-des-prompts)
3. [Gestion de sessions](#gestion-de-sessions)
4. [Gestion d'erreurs robuste](#gestion-derreurs-robuste)
5. [Configuration centralis√©e √©tendue](#configuration-centralis√©e-√©tendue)
6. [Testing et qualit√©](#testing-et-qualit√©)
7. [Performance et scalabilit√©](#performance-et-scalabilit√©)
8. [Observabilit√© et monitoring](#observabilit√©-et-monitoring)

---

## Am√©liorations prioritaires

### Matrice d'urgence/impact

| Am√©lioration | Impact | Effort | Priorit√© | Timing |
|--------------|--------|--------|----------|--------|
| S√©paration prompts | üü¢ √âlev√© | üü° Faible | **P0** | 1-2 jours |
| Gestion sessions | üî¥ Critique | üü† Moyen | **P0** | 3-5 jours |
| Gestion erreurs | üü¢ √âlev√© | üü° Faible | **P1** | 2-3 jours |
| Tests unitaires | üü¢ √âlev√© | üü† Moyen | **P1** | 1 semaine |
| Redis persistence | üü† Moyen | üü† Moyen | **P2** | 3-5 jours |
| Monitoring | üü¢ √âlev√© | üî¥ √âlev√© | **P2** | 1-2 semaines |
| Rate limiting | üü† Moyen | üü° Faible | **P2** | 1-2 jours |
| Summarization | üü† Moyen | üî¥ √âlev√© | **P3** | 1 semaine |

---

## S√©paration des prompts

### Probl√®me actuel

**Prompts hardcod√©s dans le code** :
```python
# app/agents/orchestrator.py (ligne 18)

ORCHESTRATOR_SYSTEM_PROMPT = """Tu es un copilote intelligent..."""
```

**Cons√©quences** :
- ‚ùå Modification n√©cessite red√©ploiement
- ‚ùå Pas de versioning/A/B testing
- ‚ùå Difficile de collaborer avec des non-devs (product, prompt engineers)
- ‚ùå Pas de traduction multi-langues

### Solution : Fichier d√©di√©

#### Structure propos√©e

```
app/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ closing_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ prompts/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ orchestrator_prompts.py
‚îÇ       ‚îú‚îÄ‚îÄ closing_detector_prompts.py
‚îÇ       ‚îî‚îÄ‚îÄ templates/
‚îÇ           ‚îú‚îÄ‚îÄ orchestrator_v1.txt
‚îÇ           ‚îú‚îÄ‚îÄ orchestrator_v2.txt
‚îÇ           ‚îî‚îÄ‚îÄ closing_detector_v1.txt
```

#### Impl√©mentation

```python
# app/agents/prompts/orchestrator_prompts.py

"""
Prompts pour l'agent orchestrator.

Versioning :
- v1 : Version initiale (MVP)
- v2 : Ajout de few-shot examples
- v3 : Optimisation pour r√©duire les tokens
"""

ORCHESTRATOR_SYSTEM_PROMPT_V1 = """
Tu es un copilote intelligent expert en conversation temps r√©el, sp√©cialis√© dans l'analyse et le conseil strat√©gique.

Ton r√¥le est d'√©couter une conversation en direct entre un agent et un client, et de fournir des suggestions intelligentes pour guider l'agent vers le succ√®s.

## Tes capacit√©s :

1. **Analyse de sentiment et d'intention** : Comprendre l'√©tat √©motionnel et les intentions du client
2. **D√©tection de signaux** : Identifier les objections, h√©sitations, int√©r√™ts, points √† creuser
3. **Suggestions tactiques** : Proposer les bonnes questions et relances au bon moment
4. **Orientation strat√©gique** : Recommander la direction √† prendre pour atteindre l'objectif

## Instructions :

- Analyse le contexte complet de la conversation
- Identifie les signaux cl√©s dans le dernier message (objection, int√©r√™t, confusion, etc.)
- Propose 2-3 questions pertinentes que l'agent pourrait poser
- D√©tecte les patterns √©motionnels et comportementaux
- Donne une direction strat√©gique claire et actionnable

## Format de r√©ponse :

{format_instructions}

## Contexte de la conversation :

{conversation_context}

## Dernier message analys√© :

Speaker: {speaker}
Sentiment: {sentiment}
Emotion: {emotion}
Texte: "{text}"

## Statistiques de la conversation :

{conversation_stats}

Analyse ce dernier message dans le contexte global et fournis tes suggestions au format JSON.
"""

ORCHESTRATOR_SYSTEM_PROMPT_V2 = """
Tu es un copilote intelligent expert en conversation temps r√©el.

## Contexte de la conversation :
{conversation_context}

## Dernier message :
[{speaker}] ({sentiment}, {emotion}): "{text}"

## Statistiques :
{conversation_stats}

## Ta mission :
Analyse ce message et g√©n√®re :
1. 2-3 questions tactiques pertinentes
2. Signaux cl√©s d√©tect√©s (objections, opportunit√©s, h√©sitations)
3. Direction strat√©gique claire

## Exemples :

### Exemple 1 - Objection prix :
Message client : "I'm concerned about the pricing, it seems expensive."
Ta r√©ponse :
{{
  "questions": [
    "What's your current budget range for this type of solution?",
    "How do you typically measure ROI on similar investments?"
  ],
  "signals_detected": [
    "pricing objection",
    "value concern",
    "budget sensitivity"
  ],
  "recommended_direction": "Address ROI and emphasize long-term value over upfront cost. Ask about current costs of NOT having the solution."
}}

### Exemple 2 - Int√©r√™t fort :
Message client : "This sounds exactly what we need. How quickly can we get started?"
Ta r√©ponse :
{{
  "questions": [
    "What's your ideal timeline for implementation?",
    "Who else needs to be involved in the decision?"
  ],
  "signals_detected": [
    "strong interest",
    "urgency",
    "ready to proceed"
  ],
  "recommended_direction": "Strike while iron is hot. Discuss next steps, timeline, and decision-makers. Prepare to move to closing phase."
}}

## Format de sortie :
{format_instructions}

Analyse maintenant et r√©ponds au format JSON.
"""

# Version active (facile √† changer pour A/B testing)
ORCHESTRATOR_SYSTEM_PROMPT = ORCHESTRATOR_SYSTEM_PROMPT_V1

# Mapping pour s√©lection dynamique
PROMPT_VERSIONS = {
    "v1": ORCHESTRATOR_SYSTEM_PROMPT_V1,
    "v2": ORCHESTRATOR_SYSTEM_PROMPT_V2,
}

def get_orchestrator_prompt(version: str = "v1") -> str:
    """
    R√©cup√®re une version sp√©cifique du prompt.
    
    Args:
        version: Version du prompt √† utiliser
    
    Returns:
        Prompt template string
    """
    return PROMPT_VERSIONS.get(version, ORCHESTRATOR_SYSTEM_PROMPT_V1)
```

#### Mise √† jour de l'agent

```python
# app/agents/orchestrator.py

from app.agents.prompts.orchestrator_prompts import get_orchestrator_prompt

def create_orchestrator_agent(
    memory: ConversationMemory,
    prompt_version: str = "v1"
):
    """
    Cr√©e l'agent orchestrateur.
    
    Args:
        memory: M√©moire conversationnelle
        prompt_version: Version du prompt √† utiliser (v1, v2, ...)
    """
    
    llm = ChatOpenAI(...)
    output_parser = PydanticOutputParser(...)
    
    # R√©cup√©rer le prompt selon la version
    system_prompt = get_orchestrator_prompt(version=prompt_version)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt)
    ])
    
    # ... reste du code
```

#### Configuration dans .env

```bash
# Prompt Configuration
ORCHESTRATOR_PROMPT_VERSION=v1
CLOSING_DETECTOR_PROMPT_VERSION=v1

# A/B Testing
ENABLE_PROMPT_AB_TESTING=False
PROMPT_AB_TEST_SPLIT=50  # % de trafic sur version alternative
```

#### Support A/B Testing

```python
# app/agents/orchestrator.py

import random

def create_orchestrator_agent(memory: ConversationMemory):
    """Cr√©e l'agent avec support A/B testing."""
    
    # S√©lection de version pour A/B testing
    if settings.enable_prompt_ab_testing:
        if random.randint(1, 100) <= settings.prompt_ab_test_split:
            prompt_version = "v2"  # Version exp√©rimentale
        else:
            prompt_version = "v1"  # Version de contr√¥le
    else:
        prompt_version = settings.orchestrator_prompt_version
    
    logger.info(f"Using prompt version: {prompt_version}")
    
    system_prompt = get_orchestrator_prompt(version=prompt_version)
    
    # ... reste du code
```

### Avantages de cette approche

‚úÖ **Maintenance facile** : Modifier le prompt sans toucher au code
‚úÖ **Versioning Git** : Historique complet des changements
‚úÖ **A/B Testing** : Tester plusieurs versions en production
‚úÖ **Collaboration** : Product/prompt engineers peuvent contribuer
‚úÖ **Traduction** : Support multi-langues facile
‚úÖ **Rollback rapide** : Retour √† une version ant√©rieure instantan√©

---

## Gestion de sessions

### Probl√®me actuel

**Handler global partag√©** :
```python
# app/api/websocket.py

stream_handler = StreamHandler()  # ‚ö†Ô∏è Partag√© entre tous les clients
```

**Cons√©quences** :
- ‚ùå M√©moire m√©lang√©e entre diff√©rentes conversations
- ‚ùå Impossible de g√©rer plusieurs clients simultan√©ment
- ‚ùå Pas de reprise de session apr√®s d√©connexion

### Solution : Session management

#### Architecture

```
Client 1 (WebSocket)  ‚Üí  session_id: "abc-123"  ‚Üí  StreamHandler instance 1
Client 2 (WebSocket)  ‚Üí  session_id: "def-456"  ‚Üí  StreamHandler instance 2
Client 3 (WebSocket)  ‚Üí  session_id: "ghi-789"  ‚Üí  StreamHandler instance 3
```

#### Impl√©mentation

```python
# app/api/session_manager.py

"""Gestionnaire de sessions pour isoler les conversations."""

from typing import Dict
from datetime import datetime, timedelta
import uuid
from app.handlers.stream_handler import StreamHandler
from app.utils.logger import get_logger

logger = get_logger(__name__)


class SessionManager:
    """
    G√®re les sessions de conversation.
    
    Chaque session a :
    - Un ID unique
    - Un StreamHandler d√©di√©
    - Un timestamp de derni√®re activit√©
    - Des m√©tadonn√©es (user_id, context, etc.)
    """
    
    def __init__(self, session_timeout_minutes: int = 30):
        self.sessions: Dict[str, Dict] = {}
        self.session_timeout = timedelta(minutes=session_timeout_minutes)
    
    def create_session(
        self,
        session_id: str | None = None,
        user_id: str | None = None,
        metadata: Dict | None = None
    ) -> str:
        """
        Cr√©e une nouvelle session.
        
        Args:
            session_id: ID de session (g√©n√©r√© si None)
            user_id: ID utilisateur associ√©
            metadata: M√©tadonn√©es additionnelles
        
        Returns:
            session_id
        """
        if not session_id:
            session_id = str(uuid.uuid4())
        
        if session_id in self.sessions:
            logger.warning(f"Session {session_id} existe d√©j√†, r√©utilisation")
            return session_id
        
        self.sessions[session_id] = {
            "handler": StreamHandler(),
            "created_at": datetime.utcnow(),
            "last_activity": datetime.utcnow(),
            "user_id": user_id,
            "metadata": metadata or {}
        }
        
        logger.info(f"Session cr√©√©e: {session_id} (user: {user_id})")
        return session_id
    
    def get_handler(self, session_id: str) -> StreamHandler | None:
        """
        R√©cup√®re le handler d'une session.
        
        Args:
            session_id: ID de la session
        
        Returns:
            StreamHandler ou None si session inexistante
        """
        session = self.sessions.get(session_id)
        
        if not session:
            logger.warning(f"Session {session_id} introuvable")
            return None
        
        # Mettre √† jour le timestamp d'activit√©
        session["last_activity"] = datetime.utcnow()
        
        return session["handler"]
    
    def delete_session(self, session_id: str) -> bool:
        """
        Supprime une session.
        
        Args:
            session_id: ID de la session
        
        Returns:
            True si supprim√©e, False si inexistante
        """
        if session_id in self.sessions:
            del self.sessions[session_id]
            logger.info(f"Session supprim√©e: {session_id}")
            return True
        
        return False
    
    def cleanup_expired_sessions(self):
        """Nettoie les sessions expir√©es (inactives depuis trop longtemps)."""
        now = datetime.utcnow()
        expired = []
        
        for session_id, session in self.sessions.items():
            if now - session["last_activity"] > self.session_timeout:
                expired.append(session_id)
        
        for session_id in expired:
            self.delete_session(session_id)
            logger.info(f"Session expir√©e nettoy√©e: {session_id}")
        
        return len(expired)
    
    def get_session_info(self, session_id: str) -> Dict | None:
        """R√©cup√®re les informations d'une session."""
        session = self.sessions.get(session_id)
        
        if not session:
            return None
        
        return {
            "session_id": session_id,
            "user_id": session["user_id"],
            "created_at": session["created_at"].isoformat(),
            "last_activity": session["last_activity"].isoformat(),
            "message_count": len(session["handler"].memory.messages),
            "metadata": session["metadata"]
        }
    
    def get_all_sessions(self) -> list[Dict]:
        """Liste toutes les sessions actives."""
        return [
            self.get_session_info(sid)
            for sid in self.sessions.keys()
        ]


# Instance globale
session_manager = SessionManager(session_timeout_minutes=30)
```

#### Mise √† jour WebSocket

```python
# app/api/websocket.py

from app.api.session_manager import session_manager
import asyncio

# Background task pour cleanup
async def cleanup_task():
    """Nettoie les sessions expir√©es toutes les 5 minutes."""
    while True:
        await asyncio.sleep(300)  # 5 minutes
        cleaned = session_manager.cleanup_expired_sessions()
        if cleaned > 0:
            logger.info(f"Nettoyage automatique: {cleaned} sessions expir√©es")

@router.on_event("startup")
async def start_cleanup_task():
    """D√©marre la t√¢che de nettoyage au d√©marrage."""
    asyncio.create_task(cleanup_task())


@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    """Endpoint WebSocket avec gestion de sessions."""
    
    await websocket.accept()
    
    # R√©cup√©rer ou cr√©er une session
    session_id = websocket.query_params.get("session_id")
    user_id = websocket.query_params.get("user_id")
    
    if not session_id or not session_manager.get_handler(session_id):
        # Nouvelle session
        session_id = session_manager.create_session(
            session_id=session_id,
            user_id=user_id
        )
        
        # Envoyer le session_id au client
        await websocket.send_json({
            "type": "session_init",
            "session_id": session_id,
            "message": "Session created successfully"
        })
    
    # R√©cup√©rer le handler de cette session
    handler = session_manager.get_handler(session_id)
    
    logger.info(f"Connexion WebSocket √©tablie (session: {session_id})")
    
    try:
        while True:
            data = await websocket.receive_text()
            
            try:
                json_data = json.loads(data)
                input_msg = InputMessage(**json_data)
                
                # Traiter avec le handler de cette session
                suggestion = await handler.process_message(input_msg)
                
                await websocket.send_json(suggestion.dict())
                
            except ValidationError as e:
                await websocket.send_json({
                    "error": "validation_error",
                    "details": str(e)
                })
            except Exception as e:
                await websocket.send_json({
                    "error": "processing_error",
                    "details": str(e)
                })
                logger.error(f"Erreur de traitement: {e}", exc_info=True)
    
    except WebSocketDisconnect:
        logger.info(f"Connexion ferm√©e (session: {session_id})")
        
        # Option 1 : Garder la session (reconnexion possible)
        logger.info(f"Session {session_id} conserv√©e pour reconnexion")
        
        # Option 2 : Supprimer imm√©diatement
        # session_manager.delete_session(session_id)
    
    finally:
        logger.info(f"Nettoyage connexion (session: {session_id})")


@router.get("/ws/sessions")
async def list_sessions():
    """Liste toutes les sessions actives."""
    return {
        "sessions": session_manager.get_all_sessions(),
        "total": len(session_manager.sessions)
    }


@router.get("/ws/sessions/{session_id}")
async def get_session(session_id: str):
    """R√©cup√®re les informations d'une session."""
    info = session_manager.get_session_info(session_id)
    
    if not info:
        raise HTTPException(status_code=404, detail="Session not found")
    
    return info


@router.delete("/ws/sessions/{session_id}")
async def delete_session(session_id: str):
    """Supprime une session."""
    if session_manager.delete_session(session_id):
        return {"status": "deleted", "session_id": session_id}
    else:
        raise HTTPException(status_code=404, detail="Session not found")
```

#### Client WebSocket mis √† jour

```python
# test_client.py (extrait)

import asyncio
import websockets
import json

async def test_websocket_with_session():
    """Test WebSocket avec gestion de session."""
    
    # Premi√®re connexion : cr√©ation de session
    uri = "ws://localhost:8000/ws/conversation"
    
    async with websockets.connect(uri) as websocket:
        # Recevoir le session_id
        init_msg = await websocket.recv()
        init_data = json.loads(init_msg)
        session_id = init_data["session_id"]
        
        print(f"Session cr√©√©e: {session_id}")
        
        # Envoyer quelques messages
        for i in range(3):
            message = {
                "text": f"Message {i+1}",
                "speaker": "client",
                "sentiment": "neutral",
                "emotion": "neutral"
            }
            
            await websocket.send(json.dumps(message))
            response = await websocket.recv()
            print(f"Response {i+1}: {response}")
    
    print("Connexion ferm√©e, mais session conserv√©e")
    
    # Attendre quelques secondes
    await asyncio.sleep(2)
    
    # Reconnexion avec le m√™me session_id
    uri_with_session = f"ws://localhost:8000/ws/conversation?session_id={session_id}"
    
    async with websockets.connect(uri_with_session) as websocket:
        print("Reconnect√© √† la session existante")
        
        # Continuer la conversation
        message = {
            "text": "Continuing our previous conversation",
            "speaker": "client",
            "sentiment": "positive",
            "emotion": "neutral"
        }
        
        await websocket.send(json.dumps(message))
        response = await websocket.recv()
        print(f"Response (with context): {response}")


if __name__ == "__main__":
    asyncio.run(test_websocket_with_session())
```

### Avantages de cette approche

‚úÖ **Isolation compl√®te** : Chaque client a sa propre m√©moire
‚úÖ **Reconnexion** : Reprise de session apr√®s d√©connexion
‚úÖ **Scalabilit√©** : Facilite la distribution sur plusieurs serveurs (avec Redis)
‚úÖ **Monitoring** : Tracking par session, analytics pr√©cises
‚úÖ **S√©curit√©** : Associer sessions √† des utilisateurs authentifi√©s

---

## Gestion d'erreurs robuste

### Probl√®me actuel

**Gestion d'erreurs basique** :
```python
try:
    suggestion = await handler.process_message(input_msg)
except Exception as e:
    logger.error(f"Erreur: {e}")
    # Fallback g√©n√©rique
```

**Limitations** :
- ‚ùå Pas de distinction entre types d'erreurs
- ‚ùå Messages d'erreur peu informatifs pour le client
- ‚ùå Pas de retry logic
- ‚ùå Pas de circuit breaker pour API OpenAI

### Solution : Hi√©rarchie d'exceptions custom

#### D√©finition des exceptions

```python
# app/exceptions.py

"""Exceptions custom pour gestion d'erreurs fine-grained."""

class LNGCBaseException(Exception):
    """Exception de base pour toutes les erreurs custom."""
    
    def __init__(self, message: str, details: dict | None = None):
        self.message = message
        self.details = details or {}
        super().__init__(self.message)


class ValidationException(LNGCBaseException):
    """Erreur de validation des donn√©es d'entr√©e."""
    pass


class MemoryException(LNGCBaseException):
    """Erreur li√©e √† la m√©moire conversationnelle."""
    pass


class AgentException(LNGCBaseException):
    """Erreur lors de l'invocation d'un agent."""
    pass


class LLMException(AgentException):
    """Erreur sp√©cifique au LLM (timeout, rate limit, etc.)."""
    
    def __init__(self, message: str, llm_error: Exception, details: dict | None = None):
        self.llm_error = llm_error
        super().__init__(message, details)


class OutputParsingException(AgentException):
    """Erreur de parsing de la sortie du LLM."""
    
    def __init__(self, message: str, raw_output: str, details: dict | None = None):
        self.raw_output = raw_output
        super().__init__(message, details)


class ToolException(LNGCBaseException):
    """Erreur lors de l'invocation d'un tool."""
    
    def __init__(self, message: str, tool_name: str, details: dict | None = None):
        self.tool_name = tool_name
        super().__init__(message, details)


class SessionException(LNGCBaseException):
    """Erreur li√©e aux sessions."""
    pass
```

#### Gestion d'erreurs dans l'orchestrator

```python
# app/agents/orchestrator.py

from app.exceptions import LLMException, OutputParsingException
from langchain.schema import OutputParserException
from openai import RateLimitError, APITimeoutError, APIConnectionError

async def invoke_orchestrator(
    chain,
    text: str,
    speaker: str,
    sentiment: str,
    emotion: str,
    max_retries: int = 3
) -> OutputSuggestion:
    """
    Invoque l'orchestrateur avec retry logic et gestion d'erreurs.
    """
    
    for attempt in range(max_retries):
        try:
            result = await chain.ainvoke({
                "text": text,
                "speaker": speaker,
                "sentiment": sentiment,
                "emotion": emotion
            })
            
            return result
        
        except RateLimitError as e:
            logger.warning(f"Rate limit atteint (tentative {attempt + 1}/{max_retries})")
            
            if attempt < max_retries - 1:
                # Backoff exponentiel
                wait_time = 2 ** attempt
                await asyncio.sleep(wait_time)
                continue
            else:
                raise LLMException(
                    "Rate limit exceeded after retries",
                    llm_error=e,
                    details={"attempts": max_retries}
                )
        
        except APITimeoutError as e:
            logger.warning(f"Timeout LLM (tentative {attempt + 1}/{max_retries})")
            
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
                continue
            else:
                raise LLMException(
                    "LLM timeout after retries",
                    llm_error=e,
                    details={"attempts": max_retries}
                )
        
        except APIConnectionError as e:
            logger.error(f"Erreur de connexion √† l'API OpenAI: {e}")
            raise LLMException(
                "Failed to connect to LLM API",
                llm_error=e
            )
        
        except OutputParserException as e:
            logger.error(f"Erreur de parsing de la sortie LLM: {e}")
            
            # Tenter d'extraire le JSON brut
            raw_output = str(e)
            
            raise OutputParsingException(
                "Failed to parse LLM output",
                raw_output=raw_output,
                details={"error": str(e)}
            )
        
        except Exception as e:
            logger.error(f"Erreur inattendue dans l'orchestrateur: {e}", exc_info=True)
            raise AgentException(
                "Unexpected error in orchestrator",
                details={"error": str(e), "type": type(e).__name__}
            )
    
    # Si on arrive ici, toutes les tentatives ont √©chou√©
    return OutputSuggestion(
        questions=["Could you elaborate on that?"],
        signals_detected=["processing_error"],
        recommended_direction="Continue the conversation while the system recovers."
    )
```

#### Gestion dans l'API WebSocket

```python
# app/api/websocket.py

from app.exceptions import (
    ValidationException,
    LLMException,
    OutputParsingException,
    AgentException
)

@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    # ... code connexion ...
    
    try:
        while True:
            data = await websocket.receive_text()
            
            try:
                json_data = json.loads(data)
                input_msg = InputMessage(**json_data)
                
                suggestion = await handler.process_message(input_msg)
                
                await websocket.send_json({
                    "type": "suggestion",
                    "data": suggestion.dict()
                })
            
            except ValidationError as e:
                await websocket.send_json({
                    "type": "error",
                    "error_code": "VALIDATION_ERROR",
                    "message": "Invalid input format",
                    "details": e.errors()
                })
            
            except LLMException as e:
                await websocket.send_json({
                    "type": "error",
                    "error_code": "LLM_ERROR",
                    "message": e.message,
                    "details": e.details,
                    "fallback_suggestion": {
                        "questions": ["Could you tell me more?"],
                        "signals_detected": ["llm_error"],
                        "recommended_direction": "Continue naturally."
                    }
                })
            
            except OutputParsingException as e:
                logger.error(f"Output parsing failed: {e.raw_output}")
                
                await websocket.send_json({
                    "type": "error",
                    "error_code": "PARSING_ERROR",
                    "message": "Failed to parse AI response",
                    "fallback_suggestion": {
                        "questions": ["What are your thoughts on this?"],
                        "signals_detected": ["parsing_error"],
                        "recommended_direction": "Continue the conversation."
                    }
                })
            
            except AgentException as e:
                await websocket.send_json({
                    "type": "error",
                    "error_code": "AGENT_ERROR",
                    "message": e.message,
                    "details": e.details
                })
            
            except Exception as e:
                logger.error(f"Erreur inattendue: {e}", exc_info=True)
                
                await websocket.send_json({
                    "type": "error",
                    "error_code": "INTERNAL_ERROR",
                    "message": "An unexpected error occurred",
                    "details": {"error": str(e)}
                })
    
    except WebSocketDisconnect:
        logger.info("Client disconnected")
```

### Circuit Breaker pour OpenAI API

**Objectif** : Arr√™ter temporairement les appels si l'API est down.

```python
# app/utils/circuit_breaker.py

"""Circuit Breaker pattern pour prot√©ger contre les pannes d'API."""

from enum import Enum
from datetime import datetime, timedelta
from typing import Callable, Any
import asyncio

class CircuitState(Enum):
    CLOSED = "closed"  # Normal, requ√™tes passent
    OPEN = "open"      # API down, requ√™tes bloqu√©es
    HALF_OPEN = "half_open"  # Test si API revenue


class CircuitBreaker:
    """
    Circuit Breaker pour protection contre pannes API.
    
    - CLOSED : Tout fonctionne, requ√™tes passent
    - OPEN : Trop d'erreurs, requ√™tes bloqu√©es (fallback imm√©diat)
    - HALF_OPEN : Test p√©riodique si API revenue
    """
    
    def __init__(
        self,
        failure_threshold: int = 5,
        timeout_seconds: int = 60,
        recovery_timeout: int = 30
    ):
        self.failure_threshold = failure_threshold
        self.timeout = timedelta(seconds=timeout_seconds)
        self.recovery_timeout = timedelta(seconds=recovery_timeout)
        
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.last_failure_time: datetime | None = None
        self.last_success_time: datetime | None = None
    
    async def call(self, func: Callable, *args, **kwargs) -> Any:
        """
        Ex√©cute une fonction avec protection circuit breaker.
        
        Args:
            func: Fonction async √† ex√©cuter
            *args, **kwargs: Arguments pour la fonction
        
        Returns:
            R√©sultat de la fonction
        
        Raises:
            Exception si circuit ouvert ou fonction √©choue
        """
        
        # V√©rifier l'√©tat du circuit
        if self.state == CircuitState.OPEN:
            if datetime.utcnow() - self.last_failure_time > self.recovery_timeout:
                self.state = CircuitState.HALF_OPEN
                logger.info("Circuit breaker: OPEN ‚Üí HALF_OPEN (test recovery)")
            else:
                raise Exception("Circuit breaker is OPEN (API unavailable)")
        
        try:
            # Ex√©cuter la fonction
            result = await func(*args, **kwargs)
            
            # Succ√®s : reset ou passage √† CLOSED
            self._on_success()
            
            return result
        
        except Exception as e:
            # √âchec : incr√©menter compteur
            self._on_failure()
            raise e
    
    def _on_success(self):
        """Appel√© lors d'un succ√®s."""
        self.failure_count = 0
        self.last_success_time = datetime.utcnow()
        
        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.CLOSED
            logger.info("Circuit breaker: HALF_OPEN ‚Üí CLOSED (recovery successful)")
    
    def _on_failure(self):
        """Appel√© lors d'un √©chec."""
        self.failure_count += 1
        self.last_failure_time = datetime.utcnow()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
            logger.error(
                f"Circuit breaker: ‚Üí OPEN "
                f"({self.failure_count} failures, API unavailable)"
            )


# Instance globale
openai_circuit_breaker = CircuitBreaker(
    failure_threshold=5,
    timeout_seconds=60,
    recovery_timeout=30
)
```

**Usage** :

```python
# app/agents/orchestrator.py

from app.utils.circuit_breaker import openai_circuit_breaker

async def invoke_orchestrator(...) -> OutputSuggestion:
    """Invoque avec circuit breaker."""
    
    try:
        # Wrapper la requ√™te avec circuit breaker
        result = await openai_circuit_breaker.call(
            chain.ainvoke,
            {
                "text": text,
                "speaker": speaker,
                "sentiment": sentiment,
                "emotion": emotion
            }
        )
        
        return result
    
    except Exception as e:
        if "Circuit breaker is OPEN" in str(e):
            logger.warning("OpenAI API indisponible (circuit ouvert), utilisation fallback")
            
            return OutputSuggestion(
                questions=["Tell me more about that."],
                signals_detected=["api_unavailable"],
                recommended_direction="Continue conversation (API temporarily unavailable)."
            )
        
        raise e
```

---

## Configuration centralis√©e √©tendue

### Ajout de configurations

```python
# app/config/settings.py

class Settings(BaseSettings):
    # ... configs existantes ...
    
    # Session Management
    session_timeout_minutes: int = Field(default=30, alias="SESSION_TIMEOUT_MINUTES")
    session_cleanup_interval_minutes: int = Field(default=5, alias="SESSION_CLEANUP_INTERVAL")
    
    # Error Handling
    max_retries_llm: int = Field(default=3, alias="MAX_RETRIES_LLM")
    circuit_breaker_threshold: int = Field(default=5, alias="CIRCUIT_BREAKER_THRESHOLD")
    circuit_breaker_timeout_seconds: int = Field(default=60, alias="CIRCUIT_BREAKER_TIMEOUT")
    
    # Prompt Versioning
    orchestrator_prompt_version: str = Field(default="v1", alias="ORCHESTRATOR_PROMPT_VERSION")
    enable_prompt_ab_testing: bool = Field(default=False, alias="ENABLE_PROMPT_AB_TESTING")
    prompt_ab_test_split: int = Field(default=50, alias="PROMPT_AB_TEST_SPLIT")
    
    # Rate Limiting
    rate_limit_enabled: bool = Field(default=False, alias="RATE_LIMIT_ENABLED")
    rate_limit_requests_per_minute: int = Field(default=60, alias="RATE_LIMIT_RPM")
    
    # Monitoring
    enable_metrics: bool = Field(default=False, alias="ENABLE_METRICS")
    metrics_port: int = Field(default=9090, alias="METRICS_PORT")
```

**.env exemple complet** :

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=500

# Application
APP_NAME=Call Shadow AI Agent
APP_VERSION=1.0.0
DEBUG=True
LOG_LEVEL=INFO

# API
HOST=0.0.0.0
PORT=8000
CORS_ORIGINS=["*"]

# Memory
MAX_MEMORY_MESSAGES=50
MEMORY_SUMMARY_ENABLED=False

# Sessions
SESSION_TIMEOUT_MINUTES=30
SESSION_CLEANUP_INTERVAL=5

# Error Handling
MAX_RETRIES_LLM=3
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60

# Prompts
ORCHESTRATOR_PROMPT_VERSION=v1
ENABLE_PROMPT_AB_TESTING=False
PROMPT_AB_TEST_SPLIT=50

# Rate Limiting
RATE_LIMIT_ENABLED=False
RATE_LIMIT_RPM=60

# Monitoring
ENABLE_METRICS=False
METRICS_PORT=9090

# Redis (optionnel)
REDIS_URL=redis://localhost:6379
REDIS_SESSION_TTL=86400

# PostgreSQL (optionnel)
DATABASE_URL=postgresql://user:pass@localhost/lngc_db

# Weaviate (optionnel)
WEAVIATE_URL=
WEAVIATE_API_KEY=
WEAVIATE_CLASS=ConversationKnowledge
```

---

**Suite dans le prochain document** : Testing, Performance, Monitoring

**Prochain document** : `06-SPECIFICATIONS-TECHNIQUES.md`

