# SpÃ©cifications Techniques - Ready to Implement

## ğŸ“‹ Table des matiÃ¨res

1. [SpÃ©cifications prioritaires (Sprint 1-2)](#spÃ©cifications-prioritaires-sprint-1-2)
2. [SpÃ©cifications moyenterme (Sprint 3-4)](#spÃ©cifications-moyen-terme-sprint-3-4)
3. [SpÃ©cifications long terme (Sprint 5+)](#spÃ©cifications-long-terme-sprint-5)
4. [Architecture de dÃ©ploiement](#architecture-de-dÃ©ploiement)
5. [Plan de migration](#plan-de-migration)

---

## SpÃ©cifications prioritaires (Sprint 1-2)

### SPEC-001 : SÃ©paration des prompts du code

**PrioritÃ©** : P0 (Critique)  
**Effort** : 2 jours  
**Impact** : MaintenabilitÃ©, A/B testing

#### Objectif

Externaliser tous les prompts dans des fichiers dÃ©diÃ©s pour faciliter la maintenance et le versioning.

#### TÃ¢ches

1. **CrÃ©er la structure de fichiers**
   ```
   app/agents/prompts/
   â”œâ”€â”€ __init__.py
   â”œâ”€â”€ orchestrator_prompts.py
   â”œâ”€â”€ closing_detector_prompts.py
   â””â”€â”€ templates/
       â”œâ”€â”€ orchestrator_v1.txt
       â”œâ”€â”€ orchestrator_v2.txt
       â””â”€â”€ few_shot_examples.json
   ```

2. **Migrer le prompt orchestrator**
   - Extraire `ORCHESTRATOR_SYSTEM_PROMPT` de `orchestrator.py`
   - CrÃ©er versions v1 et v2
   - ImplÃ©menter fonction `get_orchestrator_prompt(version)`

3. **Ajouter configuration versioning**
   - Variable `.env` : `ORCHESTRATOR_PROMPT_VERSION`
   - Support A/B testing avec `ENABLE_PROMPT_AB_TESTING`

4. **Tests**
   - Test unitaire : Chargement de diffÃ©rentes versions
   - Test intÃ©gration : A/B testing switch

#### CritÃ¨res d'acceptation

- âœ… Aucun prompt hardcodÃ© dans les fichiers agents
- âœ… Changement de version possible via `.env`
- âœ… A/B testing fonctionnel (50/50 split)
- âœ… Rollback instantanÃ© en cas de problÃ¨me

#### Code sample

```python
# app/agents/prompts/orchestrator_prompts.py

PROMPT_VERSIONS = {
    "v1": """...""",
    "v2": """...""",
}

def get_orchestrator_prompt(version: str = "v1") -> str:
    return PROMPT_VERSIONS.get(version, PROMPT_VERSIONS["v1"])
```

---

### SPEC-002 : Gestion de sessions utilisateurs

**PrioritÃ©** : P0 (Critique)  
**Effort** : 3-5 jours  
**Impact** : Isolation conversations, scalabilitÃ©

#### Objectif

ImplÃ©menter un gestionnaire de sessions pour isoler les conversations de chaque utilisateur.

#### TÃ¢ches

1. **CrÃ©er SessionManager**
   - Fichier : `app/api/session_manager.py`
   - MÃ©thodes : `create_session()`, `get_handler()`, `delete_session()`, `cleanup_expired_sessions()`
   - Stockage : Dict en RAM (phase 1), Redis (phase 2)

2. **Modifier WebSocket endpoint**
   - Accepter `session_id` en query param
   - CrÃ©er session si absente
   - Retourner `session_id` au client lors de l'init
   - Cleanup automatique toutes les 5 minutes

3. **Ajouter endpoints de gestion**
   - `GET /ws/sessions` : Liste sessions actives
   - `GET /ws/sessions/{id}` : DÃ©tails d'une session
   - `DELETE /ws/sessions/{id}` : Supprimer une session

4. **Tests**
   - Test : Isolation entre deux clients
   - Test : Reconnexion avec `session_id` existant
   - Test : Expiration automatique aprÃ¨s timeout

#### CritÃ¨res d'acceptation

- âœ… Chaque client a une session unique avec handler isolÃ©
- âœ… Reconnexion possible avec `session_id`
- âœ… Sessions expirÃ©es nettoyÃ©es automatiquement (30 min inactivitÃ©)
- âœ… API de monitoring des sessions actives

#### Schema de donnÃ©es

```python
{
    "session_id": "abc-123-def",
    "handler": StreamHandler instance,
    "created_at": datetime,
    "last_activity": datetime,
    "user_id": "user-456",
    "metadata": {
        "conversation_topic": "sales",
        "agent_name": "John"
    }
}
```

---

### SPEC-003 : HiÃ©rarchie d'exceptions custom

**PrioritÃ©** : P1 (Important)  
**Effort** : 2-3 jours  
**Impact** : Debugging, expÃ©rience utilisateur

#### Objectif

ImplÃ©menter une hiÃ©rarchie d'exceptions pour gestion d'erreurs fine-grained.

#### TÃ¢ches

1. **CrÃ©er fichier exceptions**
   - Fichier : `app/exceptions.py`
   - Exceptions : `LNGCBaseException`, `ValidationException`, `LLMException`, `OutputParsingException`, `ToolException`, `SessionException`

2. **ImplÃ©menter retry logic**
   - Retry automatique sur `RateLimitError` (backoff exponentiel)
   - Retry sur `APITimeoutError` (max 3 tentatives)
   - Logs dÃ©taillÃ©s pour chaque retry

3. **GÃ©rer les erreurs dans API**
   - WebSocket : Retourner JSON structurÃ© avec `error_code`, `message`, `details`
   - REST : Utiliser HTTPException avec status codes appropriÃ©s
   - Fallback suggestions en cas d'erreur LLM

4. **Tests**
   - Mock OpenAI API pour simuler erreurs
   - VÃ©rifier retry logic (3 tentatives)
   - VÃ©rifier fallback suggestions

#### CritÃ¨res d'acceptation

- âœ… Toutes les erreurs typÃ©es (pas de `Exception` gÃ©nÃ©rique)
- âœ… Retry automatique avec backoff exponentiel
- âœ… Messages d'erreur clairs pour le client
- âœ… Fallback suggestions fonctionnelles

#### Format erreur API

```json
{
  "type": "error",
  "error_code": "LLM_RATE_LIMIT",
  "message": "Rate limit exceeded, retrying...",
  "details": {
    "attempts": 2,
    "max_retries": 3
  },
  "fallback_suggestion": {
    "questions": ["Could you tell me more?"],
    "signals_detected": ["rate_limit_error"],
    "recommended_direction": "Continue naturally."
  }
}
```

---

### SPEC-004 : Tests unitaires de base

**PrioritÃ©** : P1 (Important)  
**Effort** : 1 semaine  
**Impact** : QualitÃ©, non-rÃ©gression

#### Objectif

Couvrir les composants critiques avec des tests unitaires.

#### TÃ¢ches

1. **Setup infrastructure de tests**
   - Installer pytest, pytest-asyncio, pytest-mock
   - Configurer `tests/` avec structure miroir de `app/`
   - CrÃ©er fixtures rÃ©utilisables

2. **Tests mÃ©moire conversationnelle**
   - Test : Ajout messages et gestion fenÃªtre
   - Test : GÃ©nÃ©ration contexte formatÃ©
   - Test : Statistiques conversation
   - Test : PropriÃ©tÃ©s (last_speaker, last_emotion)

3. **Tests orchestrator**
   - Test : CrÃ©ation agent avec diffÃ©rentes configs
   - Test : GÃ©nÃ©ration suggestions (mock LLM)
   - Test : Gestion erreurs output parsing
   - Test : Retry logic

4. **Tests API**
   - Test : WebSocket connexion/dÃ©connexion
   - Test : REST endpoints (process, context, summary)
   - Test : Validation Pydantic

5. **Tests session manager**
   - Test : CrÃ©ation/suppression sessions
   - Test : Cleanup automatique
   - Test : Isolation handlers

#### CritÃ¨res d'acceptation

- âœ… Couverture >= 70% sur composants critiques
- âœ… Tests passent en CI/CD
- âœ… Fixtures pour mock OpenAI API
- âœ… Documentation des tests

#### Exemple test

```python
# tests/test_memory.py

import pytest
from app.memory.conversation_memory import ConversationMemory
from app.schemas.input import InputMessage

@pytest.fixture
def memory():
    return ConversationMemory(max_messages=5)

def test_add_message_and_windowing(memory):
    """Test ajout messages et fenÃªtre glissante."""
    
    # Ajouter 7 messages (limite = 5)
    for i in range(7):
        msg = InputMessage(
            text=f"Message {i}",
            speaker="client",
            sentiment="neutral",
            emotion="neutral"
        )
        memory.add_input_message(msg)
    
    # VÃ©rifier : seulement 5 messages conservÃ©s
    assert len(memory.messages) == 5
    assert memory.messages[0].content == "Message 2"  # Les 2 premiers supprimÃ©s

@pytest.mark.asyncio
async def test_orchestrator_with_mock_llm(mocker):
    """Test orchestrator avec LLM mockÃ©."""
    
    # Mock OpenAI response
    mock_response = OutputSuggestion(
        questions=["Question 1", "Question 2"],
        signals_detected=["signal1"],
        recommended_direction="Direction"
    )
    
    mocker.patch(
        "app.agents.orchestrator.ChatOpenAI.ainvoke",
        return_value=mock_response
    )
    
    # Test
    memory = ConversationMemory()
    agent = create_orchestrator_agent(memory)
    
    result = await agent.ainvoke({
        "text": "Test message",
        "speaker": "client",
        "sentiment": "neutral",
        "emotion": "neutral"
    })
    
    assert len(result.questions) == 2
```

---

## SpÃ©cifications moyen terme (Sprint 3-4)

### SPEC-005 : IntÃ©gration Redis pour persistence sessions

**PrioritÃ©** : P2  
**Effort** : 3-5 jours  
**Impact** : ScalabilitÃ© horizontale, reconnexion robuste

#### Objectif

Stocker les sessions dans Redis pour permettre la scalabilitÃ© et la persistence.

#### Architecture

```
Client WebSocket â†’ Load Balancer
    â†’ Server 1 (lit session depuis Redis)
    â†’ Server 2 (lit session depuis Redis)
    â†’ Server 3 (lit session depuis Redis)
```

#### TÃ¢ches

1. **Setup Redis**
   - Docker compose avec Redis
   - Configuration `.env` : `REDIS_URL`, `REDIS_SESSION_TTL`
   - CrÃ©er connexion async (`redis.asyncio`)

2. **Ã‰tendre ConversationMemory**
   - MÃ©thode `save_to_redis(session_id)`
   - MÃ©thode `load_from_redis(session_id)`
   - Serialization JSON des messages

3. **Modifier SessionManager**
   - Remplacer Dict par Redis
   - Sync automatique Ã  chaque ajout de message
   - Cleanup basÃ© sur TTL Redis

4. **Tests**
   - Test : Session partagÃ©e entre 2 instances serveur
   - Test : Reconnexion aprÃ¨s restart serveur
   - Test : TTL et expiration automatique

#### CritÃ¨res d'acceptation

- âœ… Sessions persistÃ©es dans Redis
- âœ… ScalabilitÃ© horizontale (plusieurs instances serveur)
- âœ… Reconnexion robuste aprÃ¨s crash serveur
- âœ… TTL automatique configurÃ©

#### Code sample

```python
# app/memory/conversation_memory.py

import redis.asyncio as redis
import json

class ConversationMemory(BaseChatMessageHistory):
    def __init__(
        self,
        max_messages: int = 50,
        redis_client: redis.Redis = None,
        session_id: str = None
    ):
        # ... init existant ...
        self.redis_client = redis_client
        self.session_id = session_id
    
    async def add_input_message(self, input_msg: InputMessage):
        # Ajouter en mÃ©moire
        # ... code existant ...
        
        # Sync avec Redis
        if self.redis_client and self.session_id:
            await self._save_to_redis()
    
    async def _save_to_redis(self):
        key = f"session:{self.session_id}:memory"
        data = json.dumps([meta for meta in self.metadata_store])
        await self.redis_client.set(
            key,
            data,
            ex=settings.redis_session_ttl
        )
    
    async def load_from_redis(self):
        key = f"session:{self.session_id}:memory"
        data = await self.redis_client.get(key)
        
        if data:
            self.metadata_store = json.loads(data)
            # Reconstruire self.messages
            # ...
```

---

### SPEC-006 : Summarization automatique des conversations

**PrioritÃ©** : P2  
**Effort** : 1 semaine  
**Impact** : Contexte Ã©tendu sans limite de fenÃªtre

#### Objectif

ImplÃ©menter la summarization progressive pour conserver le contexte des longues conversations.

#### TÃ¢ches

1. **Algorithme de summarization**
   - DÃ©clencher quand fenÃªtre atteint 45/50 messages
   - RÃ©sumer les 15 messages les plus anciens
   - Conserver synthÃ¨se + 35 messages rÃ©cents

2. **Prompt de summarization**
   - CrÃ©er prompt dÃ©diÃ© dans `prompts/summarization_prompt.py`
   - Format : Points clÃ©s, accords, objections, Ã©volution sentiment

3. **IntÃ©gration dans mÃ©moire**
   - Ajouter champ `summary` Ã  ConversationMemory
   - MÃ©thode `summarize_oldest_messages(num_messages)`
   - Injecter synthÃ¨se en premier dans `get_context()`

4. **Configuration**
   - Variable `.env` : `MEMORY_SUMMARY_ENABLED`, `SUMMARY_TRIGGER_THRESHOLD`
   - ContrÃ´le coÃ»ts API (summarization = appel LLM supplÃ©mentaire)

#### CritÃ¨res d'acceptation

- âœ… Conversations >50 messages ne perdent pas le contexte initial
- âœ… SynthÃ¨se claire et concise (max 200 mots)
- âœ… DÃ©sactivable via config
- âœ… Monitoring du coÃ»t API de summarization

#### Format synthÃ¨se

```
[SYNTHÃˆSE CONVERSATION - Messages 1-15]
Objectif client : Ã‰valuer la solution pour Ã©quipe de 50 personnes
Points d'accord : IntÃ©rÃªt pour fonctionnalitÃ©s A et B
Objections soulevÃ©es : Prix perÃ§u comme Ã©levÃ©, besoin d'approbation manager
Ã‰volution sentiment : Positif initial â†’ HÃ©sitant sur budget â†’ Retour positif aprÃ¨s clarification ROI
```

---

### SPEC-007 : Activation Weaviate pour RAG

**PrioritÃ©** : P2  
**Effort** : 3-5 jours  
**Impact** : Suggestions basÃ©es sur base de connaissances

#### Objectif

Activer le tool Weaviate pour permettre Ã  l'agent de rechercher dans une base de connaissances.

#### TÃ¢ches

1. **Setup Weaviate**
   - Docker compose avec Weaviate
   - CrÃ©er schema : `ConversationKnowledge`
   - Importer donnÃ©es initiales (docs produit, pricing, FAQ)

2. **DÃ©commenter code du tool**
   - ImplÃ©menter `weaviate_search()` complet
   - Gestion erreurs (timeout, connexion)
   - Tests unitaires du tool

3. **Binder au LLM**
   - `llm.bind_tools([weaviate_search])`
   - Mettre Ã  jour prompt pour mentionner le tool
   - Tester invocation automatique

4. **Monitoring**
   - Logger les invocations du tool
   - Tracker pertinence des rÃ©sultats
   - MÃ©triques : Latence recherche, nb rÃ©sultats trouvÃ©s

#### CritÃ¨res d'acceptation

- âœ… Agent peut chercher dans Weaviate automatiquement
- âœ… RÃ©sultats intÃ©grÃ©s dans les suggestions
- âœ… Latence <500ms pour la recherche
- âœ… Fallback si Weaviate indisponible

#### Exemple d'usage

**Client** : "What are your enterprise pricing options?"

**Agent workflow** :
1. DÃ©tecte besoin d'info factuelle
2. Invoque `weaviate_search("enterprise pricing options", limit=3)`
3. ReÃ§oit docs pricing
4. GÃ©nÃ¨re rÃ©ponse basÃ©e sur les docs :
   ```json
   {
     "questions": [
       "How many users would be on the enterprise plan?",
       "Are you interested in annual or monthly billing?"
     ],
     "signals_detected": ["pricing inquiry", "enterprise tier interest"],
     "recommended_direction": "Based on our enterprise tier: $5000/month for up to 100 users with premium support. Clarify their team size and billing preference."
   }
   ```

---

### SPEC-008 : Rate limiting

**PrioritÃ©** : P2  
**Effort** : 1-2 jours  
**Impact** : Protection contre abus, contrÃ´le coÃ»ts

#### Objectif

ImplÃ©menter rate limiting pour protÃ©ger l'API contre les abus.

#### TÃ¢ches

1. **Middleware FastAPI**
   - Utiliser `slowapi` ou middleware custom
   - Limites : 60 req/min par IP, 1000 req/jour par utilisateur

2. **Configuration**
   - Variables `.env` : `RATE_LIMIT_ENABLED`, `RATE_LIMIT_RPM`
   - Limites diffÃ©rentes par endpoint (WebSocket vs REST)

3. **RÃ©ponse en cas de dÃ©passement**
   - HTTP 429 "Too Many Requests" (REST)
   - Message JSON avec retry-after (WebSocket)

#### CritÃ¨res d'acceptation

- âœ… Rate limiting fonctionnel sur tous les endpoints
- âœ… Headers `X-RateLimit-*` dans les rÃ©ponses
- âœ… DÃ©sactivable en dev/test
- âœ… Configurable par environnement

---

## SpÃ©cifications long terme (Sprint 5+)

### SPEC-009 : Multi-agents orchestration

**PrioritÃ©** : P3  
**Effort** : 2 semaines  
**Impact** : SpÃ©cialisation, qualitÃ© suggestions

#### Objectif

ImplÃ©menter une architecture multi-agents avec agents spÃ©cialisÃ©s coordonnÃ©s par un meta-orchestrator.

#### Architecture

```
Meta-Orchestrator
â”œâ”€â”€ Tactical Agent (questions & suggestions)
â”œâ”€â”€ Emotional Analyzer (dÃ©tection nuances Ã©motionnelles)
â”œâ”€â”€ Closing Detector (opportunitÃ©s de closing)
â””â”€â”€ Strategy Advisor (direction long-terme)
```

#### Agents Ã  crÃ©er

1. **Tactical Agent** (existant, renommer `orchestrator`)
   - Questions tactiques
   - DÃ©tection signaux immÃ©diats

2. **Emotional Analyzer** (nouveau)
   - Analyse Ã©motionnelle fine-grained
   - Tendance Ã©motionnelle (improving/degrading)
   - Score d'empathie nÃ©cessaire

3. **Closing Detector** (nouveau)
   - Score de probabilitÃ© de closing (0-100)
   - Signaux positifs vs blockers
   - Action recommandÃ©e (ask commitment, nurture, address blocker)

4. **Strategy Advisor** (nouveau)
   - Vue stratÃ©gique long-terme
   - Prochain milestone dans le funnel
   - Risques identifiÃ©s

#### TÃ¢ches

1. **CrÃ©er agents spÃ©cialisÃ©s**
   - Fichiers : `closing_detector.py`, `emotional_analyzer.py`, `strategy_advisor.py`
   - Prompts dÃ©diÃ©s pour chaque spÃ©cialisation
   - SchÃ©mas de sortie spÃ©cifiques (Pydantic)

2. **CrÃ©er MetaOrchestrator**
   - Fichier : `meta_orchestrator.py`
   - Logique de sÃ©lection d'agents selon contexte
   - ExÃ©cution parallÃ¨le (asyncio.gather)
   - Combinaison intelligente des rÃ©sultats

3. **IntÃ©grer dans StreamHandler**
   - Remplacer invocation agent unique par meta-orchestrator
   - Format de sortie combinÃ©

#### CritÃ¨res d'acceptation

- âœ… 4 agents spÃ©cialisÃ©s opÃ©rationnels
- âœ… Meta-orchestrator sÃ©lectionne agents pertinents
- âœ… ExÃ©cution parallÃ¨le (latence ~= agent le plus lent)
- âœ… Output combinÃ© cohÃ©rent

---

### SPEC-010 : Streaming token-par-token

**PrioritÃ©** : P3  
**Effort** : 1 semaine  
**Impact** : UX, perception de latence

#### Objectif

Streamer les suggestions token-par-token pour affichage progressif dans l'UI.

#### TÃ¢ches

1. **Callback LangChain**
   - CrÃ©er `WebSocketCallbackHandler`
   - Hook `on_llm_new_token()`
   - Envoyer chaque token via WebSocket

2. **Protocol WebSocket Ã©tendu**
   - Messages type `token` : `{"type": "token", "content": "...", "full_text": "..."}`
   - Message type `complete` : `{"type": "complete", "data": {...}}`

3. **Tests**
   - Mock LLM avec tokens prÃ©dÃ©finis
   - VÃ©rifier ordre et intÃ©gritÃ© des tokens

#### CritÃ¨res d'acceptation

- âœ… Tokens streamÃ©s en temps rÃ©el
- âœ… Affichage progressif dans UI
- âœ… Message "complete" Ã  la fin
- âœ… Fallback si streaming Ã©choue

---

### SPEC-011 : Dashboard de monitoring (Prometheus + Grafana)

**PrioritÃ©** : P3  
**Effort** : 1-2 semaines  
**Impact** : ObservabilitÃ© production

#### Objectif

ImplÃ©menter un dashboard de monitoring pour mÃ©triques temps rÃ©el.

#### MÃ©triques Ã  tracker

**Performance** :
- Latence moyenne par endpoint
- Latence LLM (p50, p95, p99)
- Throughput (req/sec)

**Utilisation** :
- Sessions actives
- Messages traitÃ©s/heure
- Tokens consommÃ©s (coÃ»t API)

**Erreurs** :
- Taux d'erreur par type (validation, LLM, parsing)
- Circuit breaker state changes
- Retries count

**Business** :
- Signaux dÃ©tectÃ©s (top 10)
- Sentiment distribution
- Closing score moyen

#### TÃ¢ches

1. **Setup Prometheus**
   - Installer `prometheus-client`
   - Exposer endpoint `/metrics`
   - Configurer scraping

2. **Instrumenter le code**
   - Counter : RequÃªtes totales, erreurs
   - Histogram : Latence
   - Gauge : Sessions actives, closing score

3. **Setup Grafana**
   - Dashboard "Overview"
   - Dashboard "Performance"
   - Dashboard "Business Metrics"
   - Alertes (erreurs >5%, latence >2s)

#### CritÃ¨res d'acceptation

- âœ… MÃ©triques exportÃ©es Ã  `/metrics`
- âœ… Grafana dashboard opÃ©rationnel
- âœ… Alertes configurÃ©es
- âœ… RÃ©tention 30 jours

---

### SPEC-012 : Support multi-modÃ¨les (Claude, Mistral, local)

**PrioritÃ©** : P3  
**Effort** : 1 semaine  
**Impact** : FlexibilitÃ©, rÃ©duction coÃ»ts

#### Objectif

Permettre l'utilisation de diffÃ©rents LLMs selon le besoin (Claude pour qualitÃ©, Mistral local pour coÃ»ts).

#### TÃ¢ches

1. **Abstraction LLM**
   - Factory pattern pour crÃ©ation LLM
   - Configuration `.env` : `ORCHESTRATOR_LLM_PROVIDER`, `CLOSING_DETECTOR_LLM_PROVIDER`

2. **Support providers**
   - OpenAI (existant)
   - Anthropic Claude
   - Mistral (API et local avec Ollama)
   - Fallback automatique si provider indisponible

3. **Benchmarking**
   - Script de comparaison qualitÃ©/latence/coÃ»t
   - Recommandations par use case

#### CritÃ¨res d'acceptation

- âœ… Support de 3+ providers
- âœ… Switch via config
- âœ… Fallback automatique
- âœ… Documentation benchmark

---

## Architecture de dÃ©ploiement

### Production-ready architecture

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Load Balancerâ”‚
                        â”‚   (Nginx)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                  â”‚                  â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
       â”‚ Server 1â”‚       â”‚ Server 2â”‚       â”‚ Server 3â”‚
       â”‚ (FastAPIâ”‚       â”‚ (FastAPIâ”‚       â”‚ (FastAPIâ”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
            â”‚                  â”‚                  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚                   â”‚
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
                â”‚  Redis  â”‚         â”‚Weaviateâ”‚
                â”‚(Sessionsâ”‚         â”‚  (RAG) â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ PostgreSQL  â”‚
              â”‚ (Analytics) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Compose (production)

```yaml
version: '3.8'

services:
  # Application
  lngc-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/lngc_db
      - WEAVIATE_URL=http://weaviate:8080
    depends_on:
      - redis
      - postgres
      - weaviate
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
  
  # Redis pour sessions
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
  
  # PostgreSQL pour analytics
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: lngc_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  # Weaviate pour RAG
  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
    environment:
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
    volumes:
      - weaviate_data:/var/lib/weaviate
  
  # Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
  
  # Grafana dashboards
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus

volumes:
  redis_data:
  postgres_data:
  weaviate_data:
  prometheus_data:
  grafana_data:
```

---

## Plan de migration

### Phase 1 : Stabilisation (Semaines 1-2)

**Objectifs** :
- Codebase propre et maintenable
- Tests de base en place
- Gestion d'erreurs robuste

**TÃ¢ches** :
- âœ… SPEC-001 : SÃ©paration prompts
- âœ… SPEC-002 : Gestion sessions
- âœ… SPEC-003 : Exceptions custom
- âœ… SPEC-004 : Tests unitaires

**Livrable** : Version 1.1.0 stable

---

### Phase 2 : ScalabilitÃ© (Semaines 3-4)

**Objectifs** :
- Support multi-instances
- Persistence robuste
- Protection production

**TÃ¢ches** :
- âœ… SPEC-005 : Redis integration
- âœ… SPEC-008 : Rate limiting
- âœ… DÃ©ploiement Docker Compose

**Livrable** : Version 1.2.0 production-ready

---

### Phase 3 : Enrichissement (Semaines 5-8)

**Objectifs** :
- Contexte Ã©tendu
- Base de connaissances
- ObservabilitÃ©

**TÃ¢ches** :
- âœ… SPEC-006 : Summarization
- âœ… SPEC-007 : Weaviate RAG
- âœ… SPEC-011 : Monitoring (Prometheus/Grafana)

**Livrable** : Version 2.0.0 feature-complete

---

### Phase 4 : Optimisation (Semaines 9-12)

**Objectifs** :
- Agents spÃ©cialisÃ©s
- UX amÃ©liorÃ©e
- FlexibilitÃ© maximale

**TÃ¢ches** :
- âœ… SPEC-009 : Multi-agents
- âœ… SPEC-010 : Streaming tokens
- âœ… SPEC-012 : Multi-modÃ¨les

**Livrable** : Version 2.1.0 enterprise-grade

---

## RÃ©sumÃ© exÃ©cutif

### Priorisation recommandÃ©e

| Semaine | Focus | Specs | Livrable |
|---------|-------|-------|----------|
| 1-2 | Stabilisation | 001, 002, 003, 004 | v1.1.0 |
| 3-4 | ScalabilitÃ© | 005, 008 | v1.2.0 |
| 5-6 | Contexte & RAG | 006, 007 | v2.0.0-beta |
| 7-8 | ObservabilitÃ© | 011 | v2.0.0 |
| 9-10 | Multi-agents | 009 | v2.1.0-beta |
| 11-12 | UX & FlexibilitÃ© | 010, 012 | v2.1.0 |

### Effort total estimÃ©

- **Court terme (P0-P1)** : 3-4 semaines
- **Moyen terme (P2)** : 4-5 semaines
- **Long terme (P3)** : 4-5 semaines

**Total** : ~12 semaines pour version enterprise-grade complÃ¨te

### DÃ©pendances techniques

**Infrastructure requise** :
- Redis : SPEC-005
- PostgreSQL : SPEC-011 (analytics)
- Weaviate : SPEC-007
- Prometheus + Grafana : SPEC-011

**CoÃ»ts estimÃ©s (mensuel, production)** :
- OpenAI API : $200-500 (selon volume)
- Infrastructure cloud (AWS/GCP) : $150-300
- Redis/PostgreSQL managed : $50-100
- Weaviate cloud : $100-200
- **Total** : ~$500-1100/mois

---

**Fin de la documentation technique complÃ¨te** ğŸ‰

**Documents crÃ©Ã©s** :
1. âœ… `01-ARCHITECTURE-GENERALE.md`
2. âœ… `02-WEBSOCKETS-ET-REST.md`
3. âœ… `03-MEMOIRE-CONVERSATIONNELLE.md`
4. âœ… `04-AGENTS-ET-TOOLS.md`
5. âœ… `05-EXTENSIONS-ET-AMELIORATIONS.md`
6. âœ… `06-SPECIFICATIONS-TECHNIQUES.md`

