# WebSockets et REST API - Guide DÃ©taillÃ©

## ðŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [WebSocket : Communication temps rÃ©el](#websocket--communication-temps-rÃ©el)
3. [REST API : Mode synchrone](#rest-api--mode-synchrone)
4. [Comparaison et cas d'usage](#comparaison-et-cas-dusage)
5. [Extension et intÃ©gration](#extension-et-intÃ©gration)
6. [Recevoir des donnÃ©es externes](#recevoir-des-donnÃ©es-externes)

---

## Vue d'ensemble

Le projet expose deux modes de communication pour maximiser la flexibilitÃ© :

- **WebSocket** (`ws://localhost:8000/ws/conversation`) : Connexion persistante bidirectionnelle
- **REST API** (`POST /api/process`) : RequÃªte/rÃ©ponse classique

Les deux modes **partagent le mÃªme pipeline interne** (`StreamHandler`), garantissant une logique cohÃ©rente.

---

## WebSocket : Communication temps rÃ©el

### Architecture

```
Client                          Server
  â”‚                               â”‚
  â”œâ”€â”€â”€â”€ WebSocket Handshake â”€â”€â”€â”€â”€>â”‚
  â”‚<â”€â”€â”€â”€â”€ Connection Accepted â”€â”€â”€â”€â”¤
  â”‚                               â”‚
  â”œâ”€â”€â”€â”€ JSON Message 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚                               â”œâ”€â”€ process_message()
  â”‚                               â”œâ”€â”€ invoke_orchestrator()
  â”‚<â”€â”€â”€â”€â”€ JSON Response 1 â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                               â”‚
  â”œâ”€â”€â”€â”€ JSON Message 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚                               â”œâ”€â”€ (avec contexte message 1)
  â”‚<â”€â”€â”€â”€â”€ JSON Response 2 â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                               â”‚
  â”œâ”€â”€â”€â”€ disconnect() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  Connection closed               â”‚
```

### ImplÃ©mentation dÃ©taillÃ©e

#### Code actuel (`app/api/websocket.py`)

```python
@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    """Endpoint WebSocket pour streaming temps rÃ©el."""
    
    # 1. Accepter la connexion
    await websocket.accept()
    logger.info("Connexion WebSocket Ã©tablie")
    
    try:
        # 2. Boucle infinie pour recevoir messages
        while True:
            # 3. Recevoir le message JSON brut
            data = await websocket.receive_text()
            
            try:
                # 4. Parser JSON
                json_data = json.loads(data)
                
                # 5. Valider avec Pydantic
                input_msg = InputMessage(**json_data)
                
                # 6. Traiter le message
                suggestion = await stream_handler.process_message(input_msg)
                
                # 7. Retourner la rÃ©ponse JSON
                await websocket.send_json(suggestion.dict())
                
            except ValidationError as e:
                # Gestion d'erreur : retourne JSON d'erreur
                await websocket.send_json({
                    "error": "validation_error",
                    "details": str(e)
                })
            
    except WebSocketDisconnect:
        # DÃ©connexion propre du client
        logger.info("Connexion fermÃ©e par le client")
    
    finally:
        # Nettoyage (actuellement vide, mais extensible)
        logger.info("Nettoyage de la connexion")
```

### CaractÃ©ristiques clÃ©s

#### 1. **Connexion persistante**

- Une seule connexion TCP pour toute la durÃ©e de la conversation
- Pas de handshake HTTP rÃ©pÃ©tÃ© â†’ latence minimale
- IdÃ©al pour flux continu de messages (transcription live)

#### 2. **Contexte conversationnel maintenu**

- Chaque message enrichit la mÃ©moire du `StreamHandler`
- Les suggestions futures utilisent l'historique complet
- Pas besoin d'envoyer l'historique Ã  chaque requÃªte

#### 3. **Gestion d'erreurs gracieuse**

- **Erreur de validation** : Retourne JSON d'erreur, connexion maintenue
- **Erreur de traitement** : Suggestion par dÃ©faut, connexion maintenue
- **DÃ©connexion** : Nettoyage automatique via `finally`

#### 4. **Format des messages**

**Input attendu** :
```json
{
  "text": "I'm interested but the pricing concerns me.",
  "speaker": "client",
  "sentiment": "negative",
  "emotion": "uncertain"
}
```

**Output renvoyÃ©** :
```json
{
  "questions": [
    "What specific aspect of the pricing concerns you?",
    "Would you like to see a detailed breakdown?"
  ],
  "signals_detected": [
    "pricing objection",
    "interest expressed",
    "hesitation"
  ],
  "recommended_direction": "Address pricing concerns while reinforcing value proposition."
}
```

### Endpoints auxiliaires

#### `/ws/status` (GET)

VÃ©rifier l'Ã©tat du handler WebSocket sans se connecter.

```python
@router.get("/ws/status")
async def websocket_status():
    return {
        "status": "active",
        "conversation_messages": len(stream_handler.memory.messages),
        "last_speaker": stream_handler.get_last_speaker(),
        "last_emotion": stream_handler.get_last_emotion(),
        "last_sentiment": stream_handler.get_last_sentiment()
    }
```

**Use case** : Dashboard de monitoring pour vÃ©rifier l'Ã©tat du systÃ¨me.

#### `/ws/clear` (POST)

Effacer la mÃ©moire conversationnelle.

```python
@router.post("/ws/clear")
async def clear_conversation():
    stream_handler.clear_conversation()
    return {
        "status": "cleared",
        "message": "Conversation memory has been cleared"
    }
```

**Use case** : Fin de session, dÃ©marrage d'une nouvelle conversation.

---

## Comment Ã©tendre le WebSocket

### 1. **Ajouter une gestion de sessions**

**ProblÃ¨me actuel** : Un handler global partagÃ© par tous les clients.

**Solution** : Dictionnaire de handlers par `session_id`.

```python
# app/api/websocket.py

import uuid
from typing import Dict

# Store handlers par session
handlers: Dict[str, StreamHandler] = {}

@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    # GÃ©nÃ©rer un session_id unique
    session_id = str(uuid.uuid4())
    handlers[session_id] = StreamHandler()
    
    logger.info(f"Session {session_id} crÃ©Ã©e")
    
    try:
        # Envoyer le session_id au client
        await websocket.send_json({
            "type": "session_init",
            "session_id": session_id
        })
        
        while True:
            data = await websocket.receive_text()
            json_data = json.loads(data)
            
            # Utiliser le handler de cette session
            input_msg = InputMessage(**json_data)
            suggestion = await handlers[session_id].process_message(input_msg)
            
            await websocket.send_json(suggestion.dict())
    
    except WebSocketDisconnect:
        logger.info(f"Session {session_id} fermÃ©e")
    
    finally:
        # Nettoyer la session
        if session_id in handlers:
            del handlers[session_id]
            logger.info(f"Handler session {session_id} nettoyÃ©")
```

**Avantages** :
- Isolation complÃ¨te entre clients
- PossibilitÃ© de restaurer une session (avec Redis)
- Monitoring par session

### 2. **Streaming token-par-token**

**Objectif** : Envoyer les suggestions au fur et Ã  mesure de leur gÃ©nÃ©ration (comme ChatGPT).

**ImplÃ©mentation** :

```python
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler

class WebSocketCallbackHandler(BaseCallbackHandler):
    """Callback pour streamer les tokens via WebSocket."""
    
    def __init__(self, websocket: WebSocket):
        self.websocket = websocket
        self.current_text = ""
    
    async def on_llm_new_token(self, token: str, **kwargs):
        """AppelÃ© pour chaque nouveau token gÃ©nÃ©rÃ©."""
        self.current_text += token
        await self.websocket.send_json({
            "type": "token",
            "content": token,
            "full_text": self.current_text
        })

# Dans orchestrator.py
def create_orchestrator_agent(memory: ConversationMemory, websocket: WebSocket = None):
    callbacks = []
    if websocket:
        callbacks.append(WebSocketCallbackHandler(websocket))
    
    llm = ChatOpenAI(
        model=settings.openai_model,
        streaming=True,  # Activer le streaming
        callbacks=callbacks
    )
    # ... reste du code
```

**Use case** : Affichage progressif des suggestions dans l'UI frontend.

### 3. **Authentification WebSocket**

**Objectif** : SÃ©curiser les connexions avec tokens JWT.

```python
from fastapi import WebSocket, WebSocketException, status
import jwt

async def verify_websocket_token(websocket: WebSocket):
    """VÃ©rifie le token JWT dans les query params."""
    token = websocket.query_params.get("token")
    
    if not token:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        raise WebSocketException(code=status.WS_1008_POLICY_VIOLATION)
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload["user_id"]
    except jwt.InvalidTokenError:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        raise WebSocketException(code=status.WS_1008_POLICY_VIOLATION)

@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    user_id = await verify_websocket_token(websocket)
    await websocket.accept()
    
    # CrÃ©er un handler liÃ© Ã  cet utilisateur
    handler = get_or_create_user_handler(user_id)
    # ... reste du code
```

**Use case** : Production avec authentification utilisateurs.

### 4. **Heartbeat / Keep-alive**

**Objectif** : DÃ©tecter les connexions mortes et les fermer proprement.

```python
import asyncio
from datetime import datetime, timedelta

@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    last_ping = datetime.now()
    ping_interval = 30  # secondes
    
    async def send_ping():
        while True:
            await asyncio.sleep(ping_interval)
            try:
                await websocket.send_json({"type": "ping"})
            except:
                break
    
    # Lancer le ping en background
    ping_task = asyncio.create_task(send_ping())
    
    try:
        while True:
            data = await websocket.receive_text()
            
            # RÃ©pondre aux pongs
            if data == '{"type":"pong"}':
                last_ping = datetime.now()
                continue
            
            # Traitement normal
            # ...
    
    finally:
        ping_task.cancel()
```

---

## REST API : Mode synchrone

### Architecture

```
Client                          Server
  â”‚                               â”‚
  â”œâ”€â”€â”€â”€ POST /api/process â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚     (JSON Body)                â”œâ”€â”€ Validate InputMessage
  â”‚                               â”œâ”€â”€ process_message()
  â”‚                               â”œâ”€â”€ invoke_orchestrator()
  â”‚<â”€â”€â”€â”€â”€ JSON Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                               â”‚
  Connection closed               â”‚
```

### ImplÃ©mentation dÃ©taillÃ©e

```python
# app/api/rest.py

@router.post("/process", response_model=OutputSuggestionResponse)
async def process_message(input_msg: InputMessage) -> OutputSuggestionResponse:
    """
    Traite un message unique et retourne des suggestions.
    
    Alternative REST au WebSocket pour:
    - Tests et debugging
    - IntÃ©grations simples sans WebSocket
    - Batch processing
    """
    try:
        # Traiter avec le mÃªme handler que WebSocket
        suggestion = await stream_handler.process_message(input_msg)
        
        # Convertir Pydantic v1 â†’ v2 pour FastAPI
        return OutputSuggestionResponse.from_output_suggestion(suggestion)
        
    except Exception as e:
        logger.error(f"Erreur REST: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error processing message: {str(e)}"
        )
```

### CaractÃ©ristiques clÃ©s

#### 1. **Stateless (en apparence)**

- Chaque requÃªte HTTP est indÃ©pendante
- **Mais** : Le handler partagÃ© maintient la mÃ©moire entre requÃªtes
- En production avec sessions : vraiment stateless

#### 2. **Validation automatique**

FastAPI valide automatiquement le body avec `InputMessage` :

```bash
curl -X POST "http://localhost:8000/api/process" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "I need more time to think",
    "speaker": "client",
    "sentiment": "neutral",
    "emotion": "uncertain"
  }'
```

Si validation Ã©choue â†’ HTTP 422 avec dÃ©tails des erreurs.

#### 3. **Documentation auto-gÃ©nÃ©rÃ©e**

AccÃ¨s Ã  `/docs` pour Swagger UI interactif :
- SchÃ©mas Pydantic affichÃ©s
- Tester directement depuis le navigateur
- GÃ©nÃ©ration de code client (curl, Python, JS)

### Endpoints REST disponibles

#### `POST /api/process`

Traite un message et retourne une suggestion.

**Body** : `InputMessage`  
**Response** : `OutputSuggestionResponse`  
**Status codes** :
- 200 : SuccÃ¨s
- 422 : Validation error
- 500 : Server error

#### `GET /api/conversation/context`

RÃ©cupÃ¨re le contexte complet de la conversation.

```python
@router.get("/conversation/context")
async def get_conversation_context():
    context = stream_handler.get_conversation_context()
    summary = stream_handler.get_conversation_summary()
    
    return {
        "context": context,  # Texte formatÃ©
        "summary": summary   # Statistiques
    }
```

**Response** :
```json
{
  "context": "[CLIENT] (sentiment: negative, emotion: uncertain): I'm not sure...\n[AGENT] (sentiment: positive, emotion: neutral): Let me explain...",
  "summary": {
    "total_messages": 5,
    "client_messages": 3,
    "agent_messages": 2,
    "sentiments": {"negative": 2, "positive": 2, "neutral": 1},
    "emotions": {"uncertain": 2, "neutral": 2, "joy": 1}
  }
}
```

**Use case** : Dashboard analytics, debugging, export de conversation.

#### `GET /api/conversation/summary`

Statistiques rapides sans le texte complet.

```python
@router.get("/conversation/summary")
async def get_conversation_summary():
    return {
        "summary": stream_handler.get_conversation_summary(),
        "last_speaker": stream_handler.get_last_speaker(),
        "last_emotion": stream_handler.get_last_emotion(),
        "last_sentiment": stream_handler.get_last_sentiment()
    }
```

**Use case** : Monitoring temps rÃ©el, KPIs.

#### `POST /api/conversation/clear`

Efface la mÃ©moire (identique Ã  `/ws/clear`).

---

## Comparaison et cas d'usage

### WebSocket vs REST

| CritÃ¨re | WebSocket | REST |
|---------|-----------|------|
| **Connexion** | Persistante | Ã‰phÃ©mÃ¨re |
| **Latence** | TrÃ¨s faible (< 10ms) | Moyenne (50-200ms) |
| **Overhead** | Minimal aprÃ¨s handshake | HTTP headers Ã  chaque requÃªte |
| **Contexte** | Maintenu naturellement | NÃ©cessite session/cookie |
| **ScalabilitÃ©** | Connections concurrentes limitÃ©es | TrÃ¨s scalable (stateless) |
| **Debugging** | NÃ©cessite client WS | curl, Postman, navigateur |
| **Firewall** | Parfois bloquÃ© | Toujours passÃ© |
| **Use case principal** | Conversation temps rÃ©el | Tests, batch, intÃ©grations |

### Quand utiliser WebSocket ?

âœ… **Cas d'usage idÃ©aux** :
- Transcription audio temps rÃ©el â†’ suggestions instantanÃ©es
- Dashboard live avec mise Ã  jour continue
- Chat interactif avec agent
- Streaming de tokens (rÃ©ponse progressive)

âŒ **Cas d'usage moins adaptÃ©s** :
- Batch processing de conversations historiques
- IntÃ©gration avec services sans support WebSocket
- DÃ©ploiement derriÃ¨re certains proxies/CDN restrictifs

### Quand utiliser REST ?

âœ… **Cas d'usage idÃ©aux** :
- Tests et dÃ©veloppement (curl, Postman)
- IntÃ©gration avec services tiers (webhooks)
- Analyse post-appel (une conversation complÃ¨te Ã  la fois)
- Scripts batch pour analyse de donnÃ©es

âŒ **Cas d'usage moins adaptÃ©s** :
- Streaming continu de messages
- Latence critique (< 50ms)
- Volume trÃ¨s Ã©levÃ© de requÃªtes par seconde

---

## Extension et intÃ©gration

### ScÃ©nario 1 : Ajouter un endpoint pour analyse batch

**Objectif** : Analyser une conversation complÃ¨te d'un coup.

```python
# app/schemas/input.py

class ConversationBatch(BaseModel):
    """Liste de messages Ã  analyser en batch."""
    messages: List[InputMessage]
    conversation_id: Optional[str] = None

# app/api/rest.py

@router.post("/analyze-batch")
async def analyze_batch(batch: ConversationBatch):
    """Analyse une conversation complÃ¨te et retourne un rapport."""
    
    # CrÃ©er un handler temporaire pour cette conversation
    temp_handler = StreamHandler()
    
    suggestions = []
    for msg in batch.messages:
        suggestion = await temp_handler.process_message(msg)
        suggestions.append({
            "message": msg.dict(),
            "suggestion": suggestion.dict()
        })
    
    # GÃ©nÃ©rer un rapport de synthÃ¨se
    summary = temp_handler.get_conversation_summary()
    
    return {
        "conversation_id": batch.conversation_id,
        "suggestions": suggestions,
        "summary": summary,
        "overall_sentiment": calculate_overall_sentiment(summary),
        "key_moments": identify_key_moments(suggestions)
    }
```

**Use case** : Analyser des conversations terminÃ©es pour training ou analytics.

### ScÃ©nario 2 : Webhooks pour notifier un service externe

**Objectif** : Envoyer des Ã©vÃ©nements critiques Ã  un autre service.

```python
# app/api/rest.py
import httpx

async def send_webhook(event_type: str, data: dict):
    """Envoie un Ã©vÃ©nement via webhook."""
    webhook_url = settings.webhook_url  # Dans .env
    
    if not webhook_url:
        return
    
    async with httpx.AsyncClient() as client:
        try:
            await client.post(
                webhook_url,
                json={
                    "event": event_type,
                    "timestamp": datetime.utcnow().isoformat(),
                    "data": data
                },
                timeout=5.0
            )
        except Exception as e:
            logger.warning(f"Webhook failed: {e}")

@router.post("/process")
async def process_message(input_msg: InputMessage):
    suggestion = await stream_handler.process_message(input_msg)
    
    # DÃ©tecter des Ã©vÃ©nements critiques
    if "strong objection" in suggestion.signals_detected:
        await send_webhook("critical_objection", {
            "message": input_msg.dict(),
            "suggestion": suggestion.dict()
        })
    
    return OutputSuggestionResponse.from_output_suggestion(suggestion)
```

**Use case** : Alerter un manager en temps rÃ©el sur une objection forte.

---

## Recevoir des donnÃ©es externes

### Cas d'usage : Service audio externe envoie transcriptions

**Architecture proposÃ©e** :

```
Service Audio Externe (Whisper, Deepgram...)
    â”‚
    â”‚ (Transcrit audio en temps rÃ©el)
    â”‚
    â”œâ”€â”€ Speaker diarization
    â”œâ”€â”€ Sentiment analysis
    â”œâ”€â”€ Emotion detection
    â”‚
    â–¼
[WebSocket Client dans le service audio]
    â”‚
    â”‚ Envoie JSON: { text, speaker, sentiment, emotion }
    â”‚
    â–¼
[Notre WebSocket Server: ws://lngc-service/ws/conversation]
    â”‚
    â”œâ”€â”€ Validation InputMessage
    â”œâ”€â”€ Traitement StreamHandler
    â”œâ”€â”€ GÃ©nÃ©ration suggestions
    â”‚
    â–¼
[Retour des suggestions au service audio]
    â”‚
    â–¼
[Service audio affiche dans UI ou envoie Ã  l'agent]
```

### La logique est-elle la mÃªme ?

**RÃ©ponse : OUI**, exactement la mÃªme !

Le `StreamHandler` ne se soucie pas de **qui** envoie les donnÃ©es :
- Frontend web
- Service de transcription audio
- Backend tiers
- Script Python

Tant que le JSON respecte le schÃ©ma `InputMessage`, le traitement est identique.

### ImplÃ©mentation cÃ´tÃ© service externe (exemple Python)

```python
# external_audio_service.py

import asyncio
import websockets
import json

async def send_transcription_to_lngc():
    """Service audio qui envoie ses transcriptions Ã  LNGC."""
    
    uri = "ws://lngc-service:8000/ws/conversation"
    
    async with websockets.connect(uri) as websocket:
        # Boucle de transcription
        while audio_is_streaming:
            # Obtenir la transcription du chunk audio
            transcription = await transcribe_audio_chunk()
            
            # Enrichir avec mÃ©tadonnÃ©es
            message = {
                "text": transcription.text,
                "speaker": transcription.speaker,  # "client" ou "agent"
                "sentiment": transcription.sentiment,  # Depuis modÃ¨le de sentiment
                "emotion": transcription.emotion  # Depuis modÃ¨le d'Ã©motion
            }
            
            # Envoyer Ã  LNGC
            await websocket.send(json.dumps(message))
            
            # Recevoir les suggestions
            response = await websocket.recv()
            suggestions = json.loads(response)
            
            # Utiliser les suggestions (affichage UI, TTS pour l'agent, etc.)
            await display_suggestions_to_agent(suggestions)
```

### Adaptation si le service externe ne peut pas faire WebSocket

**Solution : Exposer un endpoint REST pour recevoir des webhooks**

```python
# app/api/rest.py

@router.post("/webhook/transcription")
async def receive_transcription_webhook(input_msg: InputMessage, session_id: str):
    """
    Endpoint pour recevoir des transcriptions via webhook.
    
    Le service externe fait un POST HTTP au lieu de WebSocket.
    """
    
    # RÃ©cupÃ©rer ou crÃ©er un handler pour cette session
    if session_id not in session_handlers:
        session_handlers[session_id] = StreamHandler()
    
    handler = session_handlers[session_id]
    
    # Traiter le message
    suggestion = await handler.process_message(input_msg)
    
    # Retourner la suggestion (ou la stocker pour rÃ©cupÃ©ration ultÃ©rieure)
    return {
        "session_id": session_id,
        "suggestion": suggestion.dict()
    }
```

**CÃ´tÃ© service audio** :

```python
# external_audio_service.py

import httpx

async def send_transcription_via_http(transcription):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://lngc-service:8000/api/webhook/transcription",
            params={"session_id": "call-12345"},
            json={
                "text": transcription.text,
                "speaker": transcription.speaker,
                "sentiment": transcription.sentiment,
                "emotion": transcription.emotion
            }
        )
        
        suggestions = response.json()["suggestion"]
        await display_suggestions(suggestions)
```

---

## RÃ©sumÃ© : Choix technologique

| Besoin | Recommandation |
|--------|----------------|
| **Service audio temps rÃ©el** | WebSocket (latence minimale) |
| **Service audio via webhook** | REST avec session_id |
| **Frontend web interactif** | WebSocket |
| **Analyse batch post-appel** | REST `/analyze-batch` |
| **Tests et dÃ©veloppement** | REST (curl, Postman) |
| **Monitoring dashboard** | WebSocket (updates live) ou REST polling |

---

**Prochain document** : `03-EXTENSIONS-ET-AMELIORATIONS.md`

