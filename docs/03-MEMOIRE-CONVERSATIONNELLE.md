# M√©moire Conversationnelle - Deep Dive

## üìã Table des mati√®res

1. [Architecture de la m√©moire](#architecture-de-la-m√©moire)
2. [Impl√©mentation actuelle](#impl√©mentation-actuelle)
3. [Comment elle √©volue pendant une discussion](#comment-elle-√©volue-pendant-une-discussion)
4. [Extensions possibles](#extensions-possibles)
5. [Summarization automatique](#summarization-automatique)
6. [Persistence et scalabilit√©](#persistence-et-scalabilit√©)

---

## Architecture de la m√©moire

### Concept g√©n√©ral

La m√©moire conversationnelle est le **c≈ìur contextuel** du syst√®me. Elle permet √† l'agent de :
- Comprendre le fil de la conversation
- D√©tecter des patterns comportementaux
- G√©n√©rer des suggestions contextualis√©es
- Maintenir la coh√©rence sur toute la dur√©e de l'√©change

### Design Pattern

Le projet utilise une **m√©moire custom** h√©ritant de `BaseChatMessageHistory` de LangChain pour garantir :
- **Compatibilit√©** avec l'√©cosyst√®me LangChain
- **Flexibilit√©** pour stocker des m√©tadonn√©es riches
- **Contr√¥le** sur la gestion de la fen√™tre de contexte

---

## Impl√©mentation actuelle

### Structure de la classe

```python
class ConversationMemory(BaseChatMessageHistory):
    """
    M√©moire conversationnelle custom avec m√©tadonn√©es.
    
    Attributes:
        messages: List[BaseMessage] - Messages LangChain (HumanMessage, AIMessage)
        metadata_store: List[Dict] - M√©tadonn√©es enrichies (speaker, sentiment, emotion)
        max_messages: int - Taille max de la fen√™tre (d√©faut: 50)
    """
    
    def __init__(self, max_messages: int = 50):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.max_messages = max_messages
```

### Deux structures parall√®les

#### 1. `self.messages` : Format LangChain

Stocke les messages au format LangChain natif pour compatibilit√© :

```python
[
    HumanMessage(content="I'm interested but concerned about pricing"),
    AIMessage(content="Let me explain our pricing structure"),
    HumanMessage(content="That sounds reasonable")
]
```

**Pourquoi ?**
- Certains composants LangChain attendent ce format
- Facilite l'int√©gration de composants tiers (RAG, chains)
- Permet d'utiliser `ConversationBufferWindowMemory` en remplacement si besoin

#### 2. `self.metadata_store` : M√©tadonn√©es enrichies

Stocke les m√©tadonn√©es m√©tier ignor√©es par LangChain :

```python
[
    {
        "speaker": "client",
        "sentiment": "negative",
        "emotion": "uncertain",
        "text": "I'm interested but concerned about pricing"
    },
    {
        "speaker": "agent",
        "sentiment": "positive",
        "emotion": "neutral",
        "text": "Let me explain our pricing structure"
    }
]
```

**Pourquoi deux structures ?**
- LangChain `BaseMessage` a `additional_kwargs` mais difficile √† requ√™ter
- Acc√®s direct aux m√©tadonn√©es pour calculs (stats, filtres)
- Flexibilit√© pour ajouter des champs custom sans casser LangChain

### M√©thodes principales

#### `add_input_message(input_msg: InputMessage)`

**R√¥le** : Point d'entr√©e pour ajouter un message √† la m√©moire.

```python
def add_input_message(self, input_msg: InputMessage) -> None:
    """Ajoute un InputMessage avec conversion et m√©tadonn√©es."""
    
    # 1. Conversion en message LangChain
    if input_msg.speaker == "client":
        message = HumanMessage(content=input_msg.text)
    else:
        message = AIMessage(content=input_msg.text)
    
    # 2. Attachement des m√©tadonn√©es au message
    message.additional_kwargs = {
        "speaker": input_msg.speaker,
        "sentiment": input_msg.sentiment,
        "emotion": input_msg.emotion
    }
    
    # 3. Ajout √† la liste LangChain
    self.add_message(message)
    
    # 4. Stockage parall√®le des m√©tadonn√©es
    self.metadata_store.append({
        "speaker": input_msg.speaker,
        "sentiment": input_msg.sentiment,
        "emotion": input_msg.emotion,
        "text": input_msg.text
    })
```

**Flux** :
```
InputMessage ‚Üí Validation Pydantic ‚Üí add_input_message() ‚Üí 
    ‚Üí HumanMessage/AIMessage (+ additional_kwargs) ‚Üí self.messages
    ‚Üí Dict m√©tadonn√©es ‚Üí self.metadata_store
```

#### `add_message(message: BaseMessage)`

**R√¥le** : M√©thode bas-niveau h√©rit√©e de `BaseChatMessageHistory`.

```python
def add_message(self, message: BaseMessage) -> None:
    """Ajoute un message avec gestion de la fen√™tre."""
    self.messages.append(message)
    
    # Gestion de la fen√™tre glissante
    if len(self.messages) > self.max_messages:
        self.messages.pop(0)  # Supprimer le plus ancien
        if self.metadata_store:
            self.metadata_store.pop(0)
```

**Strat√©gie** : Fen√™tre glissante FIFO (First In First Out).

**Limitation identifi√©e** : Les messages les plus anciens sont perdus (voir Summarization).

#### `get_context(max_messages: int | None = None)`

**R√¥le** : G√©n√®re un contexte textuel format√© pour injection dans le prompt.

```python
def get_context(self, max_messages: int | None = None) -> str:
    """Formate l'historique en texte lisible."""
    
    messages_to_use = self.messages[-max_messages:] if max_messages else self.messages
    metadata_to_use = self.metadata_store[-max_messages:] if max_messages else self.metadata_store
    
    context_lines = []
    for msg, meta in zip(messages_to_use, metadata_to_use):
        context_lines.append(
            f"[{meta['speaker'].upper()}] "
            f"(sentiment: {meta['sentiment']}, emotion: {meta['emotion']}): "
            f"{msg.content}"
        )
    
    return "\n".join(context_lines)
```

**Output exemple** :
```
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
[AGENT] (sentiment: positive, emotion: joy): Great! Let me show you our features.
[CLIENT] (sentiment: negative, emotion: uncertain): I'm worried about the cost.
```

**Usage** : Inject√© dans le prompt system de l'orchestrator.

#### `get_conversation_summary()`

**R√¥le** : G√©n√®re des statistiques agr√©g√©es de la conversation.

```python
def get_conversation_summary(self) -> Dict[str, Any]:
    """Calcule des m√©triques sur la conversation."""
    
    sentiments = {}
    emotions = {}
    client_count = 0
    agent_count = 0
    
    for meta in self.metadata_store:
        # Compter par speaker
        if meta["speaker"] == "client":
            client_count += 1
        else:
            agent_count += 1
        
        # Compter sentiments
        sentiment = meta["sentiment"]
        sentiments[sentiment] = sentiments.get(sentiment, 0) + 1
        
        # Compter √©motions
        emotion = meta["emotion"]
        emotions[emotion] = emotions.get(emotion, 0) + 1
    
    return {
        "total_messages": len(self.metadata_store),
        "client_messages": client_count,
        "agent_messages": agent_count,
        "sentiments": sentiments,
        "emotions": emotions
    }
```

**Output exemple** :
```json
{
  "total_messages": 10,
  "client_messages": 6,
  "agent_messages": 4,
  "sentiments": {
    "positive": 3,
    "negative": 4,
    "neutral": 3
  },
  "emotions": {
    "uncertain": 3,
    "joy": 2,
    "neutral": 4,
    "anger": 1
  }
}
```

**Usage** :
- Inject√© dans le prompt pour contexte quantitatif
- Expos√© via API REST (`/api/conversation/summary`)
- Base pour analytics et dashboards

#### Propri√©t√©s utilitaires

```python
@property
def last_speaker(self) -> str | None:
    """Dernier speaker (client/agent)."""
    return self.metadata_store[-1]["speaker"] if self.metadata_store else None

@property
def last_emotion(self) -> str | None:
    """Derni√®re √©motion d√©tect√©e."""
    return self.metadata_store[-1]["emotion"] if self.metadata_store else None

@property
def last_sentiment(self) -> str | None:
    """Dernier sentiment d√©tect√©."""
    return self.metadata_store[-1]["sentiment"] if self.metadata_store else None
```

**Usage** : Endpoints `/ws/status`, `/api/conversation/summary` pour monitoring rapide.

---

## Comment elle √©volue pendant une discussion

### Sc√©nario complet : Conversation de vente

#### √âtat initial : M√©moire vide

```python
memory.messages = []
memory.metadata_store = []
```

#### Message 1 : Client entre en contact

**Input** :
```json
{
  "text": "Hello, I'm interested in your product.",
  "speaker": "client",
  "sentiment": "positive",
  "emotion": "neutral"
}
```

**√âtat m√©moire apr√®s traitement** :
```python
memory.messages = [
    HumanMessage(
        content="Hello, I'm interested in your product.",
        additional_kwargs={
            "speaker": "client",
            "sentiment": "positive",
            "emotion": "neutral"
        }
    )
]

memory.metadata_store = [
    {
        "speaker": "client",
        "sentiment": "positive",
        "emotion": "neutral",
        "text": "Hello, I'm interested in your product."
    }
]
```

**Contexte pour prompt** :
```
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
```

**Statistiques** :
```json
{
  "total_messages": 1,
  "client_messages": 1,
  "agent_messages": 0,
  "sentiments": {"positive": 1},
  "emotions": {"neutral": 1}
}
```

#### Message 2 : Agent r√©pond

**Input** :
```json
{
  "text": "Great! Let me explain our key features.",
  "speaker": "agent",
  "sentiment": "positive",
  "emotion": "joy"
}
```

**√âtat m√©moire apr√®s traitement** :
```python
memory.messages = [
    HumanMessage(...),  # Message 1
    AIMessage(
        content="Great! Let me explain our key features.",
        additional_kwargs={
            "speaker": "agent",
            "sentiment": "positive",
            "emotion": "joy"
        }
    )
]
```

**Contexte pour prompt** :
```
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
[AGENT] (sentiment: positive, emotion: joy): Great! Let me explain our key features.
```

**Statistiques** :
```json
{
  "total_messages": 2,
  "client_messages": 1,
  "agent_messages": 1,
  "sentiments": {"positive": 2},
  "emotions": {"neutral": 1, "joy": 1}
}
```

#### Message 3 : Client exprime une objection

**Input** :
```json
{
  "text": "I'm concerned about the pricing. It seems expensive.",
  "speaker": "client",
  "sentiment": "negative",
  "emotion": "uncertain"
}
```

**Contexte pour prompt** (3 messages) :
```
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
[AGENT] (sentiment: positive, emotion: joy): Great! Let me explain our key features.
[CLIENT] (sentiment: negative, emotion: uncertain): I'm concerned about the pricing. It seems expensive.
```

**Statistiques** :
```json
{
  "total_messages": 3,
  "client_messages": 2,
  "agent_messages": 1,
  "sentiments": {"positive": 2, "negative": 1},
  "emotions": {"neutral": 1, "joy": 1, "uncertain": 1}
}
```

**Impact sur les suggestions** :
L'agent orchestrateur voit :
- Changement de sentiment (positive ‚Üí negative)
- Apparition d'√©motion "uncertain"
- Mot-cl√© "pricing" avec "expensive"

Suggestions g√©n√©r√©es :
```json
{
  "questions": [
    "What specific aspect of the pricing concerns you?",
    "Have you compared it with similar solutions?"
  ],
  "signals_detected": [
    "pricing objection",
    "hesitation",
    "concern about value"
  ],
  "recommended_direction": "Address pricing concerns by emphasizing ROI and value proposition."
}
```

#### Messages 4-50 : Conversation continue

La m√©moire s'enrichit progressivement jusqu'√† la limite (`max_messages=50`).

#### Message 51 : Fen√™tre glissante activ√©e

**Comportement** :
- Message 1 (le plus ancien) est supprim√©
- Message 51 est ajout√©
- Fen√™tre = messages 2-51

**Code responsable** :
```python
if len(self.messages) > self.max_messages:
    self.messages.pop(0)
    self.metadata_store.pop(0)
```

**Limitation** : Les informations du d√©but de conversation sont perdues d√©finitivement.

---

## Extensions possibles

### 1. **D√©tection de patterns conversationnels**

**Objectif** : Identifier des patterns r√©currents (objections r√©p√©t√©es, h√©sitations croissantes).

```python
# app/memory/conversation_memory.py

def detect_emotion_trend(self) -> str:
    """D√©tecte si l'√©motion du client s'am√©liore ou se d√©grade."""
    
    if len(self.metadata_store) < 3:
        return "insufficient_data"
    
    # R√©cup√©rer les 5 derni√®res √©motions du client
    client_emotions = [
        meta["emotion"] for meta in self.metadata_store[-5:]
        if meta["speaker"] == "client"
    ]
    
    # Scorer les √©motions (positif = bon, n√©gatif = mauvais)
    emotion_scores = {
        "joy": 2, "neutral": 0, "uncertain": -1, "anger": -2, "frustration": -2
    }
    
    scores = [emotion_scores.get(e, 0) for e in client_emotions]
    
    # Calculer la tendance
    if len(scores) >= 3:
        if scores[-1] > scores[0]:
            return "improving"
        elif scores[-1] < scores[0]:
            return "degrading"
    
    return "stable"

def get_repeated_objections(self) -> List[str]:
    """Identifie les objections mentionn√©es plusieurs fois."""
    
    keywords = {
        "pricing": ["price", "cost", "expensive", "budget"],
        "features": ["feature", "functionality", "capability"],
        "timeline": ["time", "delay", "when", "schedule"]
    }
    
    objections_count = {key: 0 for key in keywords}
    
    for meta in self.metadata_store:
        if meta["speaker"] == "client" and meta["sentiment"] == "negative":
            text_lower = meta["text"].lower()
            for objection_type, terms in keywords.items():
                if any(term in text_lower for term in terms):
                    objections_count[objection_type] += 1
    
    return [
        objection for objection, count in objections_count.items()
        if count >= 2  # Mentionn√© au moins 2 fois
    ]
```

**Usage dans l'orchestrator** :
```python
def prepare_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:
    # ... code existant ...
    
    # Ajouter les patterns d√©tect√©s
    emotion_trend = memory.detect_emotion_trend()
    repeated_objections = memory.get_repeated_objections()
    
    return {
        # ... champs existants ...
        "emotion_trend": emotion_trend,  # Inject√© dans le prompt
        "repeated_objections": repeated_objections
    }
```

**Prompt enrichi** :
```
## Patterns d√©tect√©s :
- Tendance √©motionnelle : {emotion_trend}
- Objections r√©p√©t√©es : {repeated_objections}

Prends en compte ces patterns pour affiner tes suggestions.
```

### 2. **Indexation par timestamps**

**Objectif** : Ajouter des timestamps pour analyses temporelles.

```python
from datetime import datetime

class ConversationMemory(BaseChatMessageHistory):
    def __init__(self, max_messages: int = 50):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.timestamps: List[datetime] = []  # Nouveau
        self.max_messages = max_messages
    
    def add_input_message(self, input_msg: InputMessage) -> None:
        # ... code existant ...
        
        # Ajouter le timestamp
        self.timestamps.append(datetime.utcnow())
        
        # G√©rer la fen√™tre
        if len(self.messages) > self.max_messages:
            self.messages.pop(0)
            self.metadata_store.pop(0)
            self.timestamps.pop(0)  # Supprimer aussi le timestamp
    
    def get_conversation_duration(self) -> float:
        """Dur√©e totale de la conversation en minutes."""
        if len(self.timestamps) < 2:
            return 0.0
        
        duration = self.timestamps[-1] - self.timestamps[0]
        return duration.total_seconds() / 60
    
    def get_message_rate(self) -> float:
        """Messages par minute."""
        duration = self.get_conversation_duration()
        if duration == 0:
            return 0.0
        
        return len(self.messages) / duration
```

**Use case** :
- D√©tecter si la conversation s'√©ternise (fatigue)
- Identifier les moments de silence (h√©sitation)
- Calculer des KPIs temporels

### 3. **Filtrage et recherche**

**Objectif** : R√©cup√©rer des sous-ensembles de la m√©moire.

```python
def get_messages_by_speaker(self, speaker: str) -> List[Dict[str, Any]]:
    """R√©cup√®re tous les messages d'un speaker donn√©."""
    return [
        meta for meta in self.metadata_store
        if meta["speaker"] == speaker
    ]

def get_messages_by_sentiment(self, sentiment: str) -> List[Dict[str, Any]]:
    """R√©cup√®re tous les messages d'un sentiment donn√©."""
    return [
        meta for meta in self.metadata_store
        if meta["sentiment"] == sentiment
    ]

def search_keywords(self, keywords: List[str]) -> List[Dict[str, Any]]:
    """Recherche des mots-cl√©s dans l'historique."""
    results = []
    for meta in self.metadata_store:
        text_lower = meta["text"].lower()
        if any(kw.lower() in text_lower for kw in keywords):
            results.append(meta)
    return results
```

**Use case** :
- Analytics post-conversation
- Debugging de comportements inattendus
- Formation d'agents (identifier bonnes/mauvaises r√©ponses)

---

## Summarization automatique

### Probl√®me : Fen√™tre de contexte limit√©e

Avec `max_messages=50`, les messages 1-X sont perdus d√®s que la conversation d√©passe 50 messages.

**Cons√©quence** :
- Perte d'informations importantes du d√©but (contexte initial, accord sur objectifs)
- L'agent "oublie" ce qui a √©t√© dit il y a longtemps

### Solution 1 : Summarization progressive

**Concept** : Quand la fen√™tre atteint la limite, r√©sumer les N messages les plus anciens en un seul message de synth√®se.

#### Impl√©mentation

```python
# app/memory/conversation_memory.py

class ConversationMemory(BaseChatMessageHistory):
    def __init__(self, max_messages: int = 50):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.max_messages = max_messages
        self.summary: str = ""  # Synth√®se progressive
        self.summarization_enabled: bool = settings.memory_summary_enabled
    
    async def summarize_oldest_messages(self, num_messages: int = 10):
        """R√©sume les N messages les plus anciens."""
        
        if len(self.messages) < num_messages:
            return
        
        # Extraire les messages √† r√©sumer
        messages_to_summarize = self.messages[:num_messages]
        context_to_summarize = self.get_context(max_messages=num_messages)
        
        # Utiliser un LLM pour r√©sumer
        summary_prompt = f"""
        Voici le d√©but d'une conversation. R√©sume les points cl√©s en 2-3 phrases :
        - Objectif initial du client
        - Points d'accord
        - Objections soulev√©es
        
        Conversation :
        {context_to_summarize}
        
        R√©sum√© concis :
        """
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        summary = await llm.apredict(summary_prompt)
        
        # Mettre √† jour la synth√®se globale
        if self.summary:
            self.summary += f"\n\n{summary}"
        else:
            self.summary = summary
        
        # Supprimer les messages r√©sum√©s
        self.messages = self.messages[num_messages:]
        self.metadata_store = self.metadata_store[num_messages:]
        
        logger.info(f"R√©sum√© cr√©√© : {summary[:100]}...")
    
    def get_context(self, max_messages: int | None = None) -> str:
        """Contexte avec synth√®se int√©gr√©e."""
        
        # Si une synth√®se existe, l'inclure en premier
        context_parts = []
        
        if self.summary:
            context_parts.append(f"[SYNTH√àSE] : {self.summary}\n")
        
        # Ajouter les messages r√©cents
        messages_to_use = self.messages[-max_messages:] if max_messages else self.messages
        metadata_to_use = self.metadata_store[-max_messages:] if max_messages else self.metadata_store
        
        for msg, meta in zip(messages_to_use, metadata_to_use):
            context_parts.append(
                f"[{meta['speaker'].upper()}] "
                f"(sentiment: {meta['sentiment']}, emotion: {meta['emotion']}): "
                f"{msg.content}"
            )
        
        return "\n".join(context_parts)
```

#### D√©clenchement automatique

```python
# app/handlers/stream_handler.py

async def process_message(self, input_msg: InputMessage) -> OutputSuggestion:
    # Ajouter le message
    self.memory.add_input_message(input_msg)
    
    # V√©rifier si summarization n√©cessaire
    if self.memory.summarization_enabled:
        if len(self.memory.messages) >= self.memory.max_messages - 10:
            await self.memory.summarize_oldest_messages(num_messages=15)
            logger.info("Summarization automatique effectu√©e")
    
    # Continuer le traitement normal
    suggestion = await invoke_orchestrator(...)
    return suggestion
```

**Avantages** :
- Contexte complet conserv√© (synth√®se + messages r√©cents)
- Pas de perte d'information critique
- Fen√™tre de contexte toujours sous la limite

**Inconv√©nients** :
- Co√ªt API suppl√©mentaire (appel LLM pour summarizer)
- Latence ajout√©e lors de la summarization
- Risque de perte de nuances dans la synth√®se

### Solution 2 : Summarization hi√©rarchique

**Concept** : Plusieurs niveaux de synth√®se (court, moyen, long terme).

```python
class ConversationMemory(BaseChatMessageHistory):
    def __init__(self, max_messages: int = 50):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.max_messages = max_messages
        
        # Synth√®ses multi-niveaux
        self.short_term_summary: str = ""   # Derniers 50 messages
        self.medium_term_summary: str = ""  # Messages 51-150
        self.long_term_summary: str = ""    # D√©but de conversation
```

**Workflow** :
1. Messages 1-50 : Stockage complet
2. Messages 51-100 : R√©sumer 1-50 ‚Üí `long_term_summary`, garder 51-100
3. Messages 101-150 : R√©sumer 51-100 ‚Üí `medium_term_summary`, garder 101-150
4. Messages 151+ : R√©sumer 101-150 ‚Üí `short_term_summary`, garder 151+

**Prompt final** :
```
## Contexte historique :
Long terme : {long_term_summary}
Moyen terme : {medium_term_summary}

## Conversation r√©cente :
{derniers 50 messages complets}
```

### Solution 3 : Hybrid - Storage externe + Synth√®se

**Concept** : Stocker tous les messages dans une DB, mais n'injecter qu'une synth√®se + contexte r√©cent dans le prompt.

```python
# app/memory/conversation_memory.py

import asyncpg  # PostgreSQL async

class ConversationMemory(BaseChatMessageHistory):
    def __init__(self, max_messages: int = 50, db_pool=None):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.max_messages = max_messages
        self.db_pool = db_pool  # Connexion PostgreSQL
        self.conversation_id: str = None
    
    async def add_input_message(self, input_msg: InputMessage) -> None:
        # Ajouter en m√©moire (RAM)
        # ... code existant ...
        
        # Persister dans la DB
        if self.db_pool and self.conversation_id:
            await self._persist_to_db(input_msg)
    
    async def _persist_to_db(self, input_msg: InputMessage):
        """Sauvegarde le message dans PostgreSQL."""
        async with self.db_pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO conversation_messages 
                (conversation_id, speaker, text, sentiment, emotion, timestamp)
                VALUES ($1, $2, $3, $4, $5, NOW())
                """,
                self.conversation_id,
                input_msg.speaker,
                input_msg.text,
                input_msg.sentiment,
                input_msg.emotion
            )
    
    async def load_full_history_from_db(self) -> List[Dict]:
        """R√©cup√®re tous les messages depuis la DB."""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT * FROM conversation_messages
                WHERE conversation_id = $1
                ORDER BY timestamp ASC
                """,
                self.conversation_id
            )
            return [dict(row) for row in rows]
```

**Avantages** :
- Historique complet conserv√© pour analytics
- M√©moire RAM limit√©e (seulement 50 messages r√©cents)
- Possibilit√© de g√©n√©rer synth√®ses √† la demande

---

## Persistence et scalabilit√©

### Probl√®me actuel : M√©moire volatile (RAM)

**Limitations** :
- Perte de tout l'historique au restart du serveur
- Impossible d'analyser les conversations apr√®s coup
- Pas de reprise de session (reconnexion = nouvelle conversation)

### Solution 1 : Redis pour sessions temps r√©el

**Architecture** :

```
WebSocket Connection (session_id: "abc-123")
    ‚îÇ
    ‚ñº
StreamHandler (en RAM pour latence minimale)
    ‚îÇ
    ‚îú‚îÄ‚îÄ Chaque message ajout√© ‚Üí Background task : Sync avec Redis
    ‚îÇ
    ‚ñº
Redis (cache distribu√©)
    Key: "session:abc-123:messages"
    Value: JSON serialized de metadata_store
    TTL: 24 heures
```

**Impl√©mentation** :

```python
# app/memory/conversation_memory.py

import redis.asyncio as redis
import json

class ConversationMemory(BaseChatMessageHistory):
    def __init__(
        self,
        max_messages: int = 50,
        redis_client: redis.Redis = None,
        session_id: str = None
    ):
        self.messages: List[BaseMessage] = []
        self.metadata_store: List[Dict[str, Any]] = []
        self.max_messages = max_messages
        self.redis_client = redis_client
        self.session_id = session_id
    
    async def add_input_message(self, input_msg: InputMessage) -> None:
        # Ajouter en m√©moire
        # ... code existant ...
        
        # Synchroniser avec Redis (async, non-bloquant)
        if self.redis_client and self.session_id:
            asyncio.create_task(self._sync_to_redis())
    
    async def _sync_to_redis(self):
        """Sauvegarde la m√©moire dans Redis."""
        key = f"session:{self.session_id}:messages"
        data = json.dumps(self.metadata_store)
        
        await self.redis_client.set(
            key,
            data,
            ex=86400  # TTL: 24 heures
        )
    
    async def load_from_redis(self):
        """Restaure la m√©moire depuis Redis."""
        if not self.redis_client or not self.session_id:
            return
        
        key = f"session:{self.session_id}:messages"
        data = await self.redis_client.get(key)
        
        if data:
            self.metadata_store = json.loads(data)
            
            # Reconstruire les messages LangChain
            for meta in self.metadata_store:
                if meta["speaker"] == "client":
                    msg = HumanMessage(content=meta["text"])
                else:
                    msg = AIMessage(content=meta["text"])
                
                msg.additional_kwargs = {
                    "speaker": meta["speaker"],
                    "sentiment": meta["sentiment"],
                    "emotion": meta["emotion"]
                }
                
                self.messages.append(msg)
            
            logger.info(f"Session {self.session_id} restaur√©e ({len(self.messages)} messages)")
```

**Usage** :

```python
# app/api/websocket.py

import redis.asyncio as redis

# Initialiser Redis au d√©marrage
redis_client = redis.from_url("redis://localhost:6379")

@router.websocket("/ws/conversation")
async def websocket_conversation_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    # G√©n√©rer ou r√©cup√©rer session_id
    session_id = websocket.query_params.get("session_id", str(uuid.uuid4()))
    
    # Cr√©er le handler avec Redis
    handler = StreamHandler(
        redis_client=redis_client,
        session_id=session_id
    )
    
    # Charger l'historique si session existante
    await handler.memory.load_from_redis()
    
    # ... reste du code ...
```

**Avantages** :
- Reconnexion possible (reprendre la conversation)
- Scalabilit√© horizontale (plusieurs instances de serveur)
- TTL automatique (nettoyage des vieilles sessions)

### Solution 2 : PostgreSQL pour historique long-terme

**Architecture** :

```
Redis (sessions actives, < 24h)
    ‚Üì (√† la fin de la session)
PostgreSQL (historique complet, permanent)
    ‚Üì
Analytics / Data Warehouse
```

**Sch√©ma DB** :

```sql
CREATE TABLE conversations (
    conversation_id UUID PRIMARY KEY,
    user_id UUID,
    started_at TIMESTAMP DEFAULT NOW(),
    ended_at TIMESTAMP,
    total_messages INT,
    outcome VARCHAR(50)  -- "success", "objection", "abandoned"
);

CREATE TABLE conversation_messages (
    id SERIAL PRIMARY KEY,
    conversation_id UUID REFERENCES conversations(conversation_id),
    speaker VARCHAR(10),  -- "client" ou "agent"
    text TEXT,
    sentiment VARCHAR(20),
    emotion VARCHAR(20),
    timestamp TIMESTAMP DEFAULT NOW(),
    INDEX idx_conversation (conversation_id),
    INDEX idx_timestamp (timestamp)
);

CREATE TABLE conversation_suggestions (
    id SERIAL PRIMARY KEY,
    conversation_id UUID REFERENCES conversations(conversation_id),
    message_id INT REFERENCES conversation_messages(id),
    questions JSONB,
    signals_detected JSONB,
    recommended_direction TEXT,
    timestamp TIMESTAMP DEFAULT NOW()
);
```

**Workflow complet** :

1. **Connexion WebSocket** : Cr√©er session Redis
2. **Pendant la conversation** : M√©moire RAM + sync Redis en background
3. **D√©connexion / Timeout** : Flush Redis ‚Üí PostgreSQL
4. **Analytics** : Requ√™tes sur PostgreSQL

---

## Configuration recommand√©e

### `.env` √©tendu

```bash
# Memory Configuration
MAX_MEMORY_MESSAGES=50
MEMORY_SUMMARY_ENABLED=True  # Activer summarization automatique

# Redis (sessions)
REDIS_URL=redis://localhost:6379
REDIS_SESSION_TTL=86400  # 24 heures

# PostgreSQL (historique)
DATABASE_URL=postgresql://user:pass@localhost/lngc_db
DATABASE_POOL_SIZE=10
```

### `app/config/settings.py` √©tendu

```python
class Settings(BaseSettings):
    # ... config existante ...
    
    # Memory
    max_memory_messages: int = Field(default=50, alias="MAX_MEMORY_MESSAGES")
    memory_summary_enabled: bool = Field(default=False, alias="MEMORY_SUMMARY_ENABLED")
    
    # Redis
    redis_url: str | None = Field(default=None, alias="REDIS_URL")
    redis_session_ttl: int = Field(default=86400, alias="REDIS_SESSION_TTL")
    
    # PostgreSQL
    database_url: str | None = Field(default=None, alias="DATABASE_URL")
    database_pool_size: int = Field(default=10, alias="DATABASE_POOL_SIZE")
```

---

## R√©sum√© : √âvolution de la m√©moire

| Phase | Impl√©mentation | Avantages | Limitations |
|-------|----------------|-----------|-------------|
| **MVP (actuel)** | RAM, fen√™tre glissante | Simple, rapide | Volatile, perte d'historique |
| **Phase 2** | RAM + Summarization | Contexte √©tendu | Co√ªt API, latence |
| **Phase 3** | Redis pour sessions | Reconnexion, scalabilit√© | Infrastructure |
| **Phase 4** | PostgreSQL pour analytics | Historique complet | Complexit√© |

---

**Prochain document** : `04-AGENTS-ET-TOOLS.md`

