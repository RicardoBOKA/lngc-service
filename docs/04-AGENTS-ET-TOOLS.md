# Agents et Tools - Architecture Modulaire

## üìã Table des mati√®res

1. [Architecture agents actuelle](#architecture-agents-actuelle)
2. [Comment ajouter de nouveaux agents](#comment-ajouter-de-nouveaux-agents)
3. [Syst√®me de tools](#syst√®me-de-tools)
4. [Comment √©tendre ou remplacer les tools](#comment-√©tendre-ou-remplacer-les-tools)
5. [Multi-agents orchestration](#multi-agents-orchestration)
6. [Best practices](#best-practices)

---

## Architecture agents actuelle

### Agent Orchestrator : Le cerveau du syst√®me

**Fichier** : `app/agents/orchestrator.py`

**R√¥le** : Agent principal qui analyse la conversation et g√©n√®re des suggestions structur√©es.

#### Anatomie de l'agent

```python
def create_orchestrator_agent(memory: ConversationMemory):
    """
    Cr√©e l'agent orchestrateur avec LCEL.
    
    Pipeline : prepare_inputs | prompt | llm | output_parser
    """
    
    # 1. LLM : Le mod√®le de langage
    llm = ChatOpenAI(
        model=settings.openai_model,        # "gpt-4o-mini"
        temperature=settings.openai_temperature,  # 0.7 (cr√©ativit√©)
        max_tokens=settings.openai_max_tokens,    # 500
        api_key=settings.openai_api_key
    )
    
    # 2. Output Parser : Validation structur√©e
    output_parser = PydanticOutputParser(pydantic_object=OutputSuggestion)
    
    # 3. Prompt Template : Instructions syst√®me
    prompt = ChatPromptTemplate.from_messages([
        ("system", ORCHESTRATOR_SYSTEM_PROMPT),
    ])
    
    # 4. Input Preparation : Enrichissement contextuel
    def prepare_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "text": inputs["text"],
            "speaker": inputs["speaker"],
            "sentiment": inputs["sentiment"],
            "emotion": inputs["emotion"],
            "conversation_context": memory.get_context(max_messages=20),
            "conversation_stats": format_stats(memory.get_conversation_summary()),
            "format_instructions": output_parser.get_format_instructions()
        }
    
    # 5. Composition LCEL : Pipeline d√©claratif
    chain = (
        RunnableLambda(prepare_inputs)  # √âtape 1 : Enrichir inputs
        | prompt                         # √âtape 2 : Construire prompt
        | llm                            # √âtape 3 : G√©n√©rer r√©ponse
        | output_parser                  # √âtape 4 : Parser JSON ‚Üí Pydantic
    )
    
    return chain
```

### D√©composition du pipeline LCEL

#### 1. `RunnableLambda(prepare_inputs)`

**R√¥le** : Transformer les inputs bruts en inputs enrichis pour le prompt.

**Input** :
```python
{
    "text": "I'm concerned about pricing",
    "speaker": "client",
    "sentiment": "negative",
    "emotion": "uncertain"
}
```

**Output** :
```python
{
    "text": "I'm concerned about pricing",
    "speaker": "client",
    "sentiment": "negative",
    "emotion": "uncertain",
    "conversation_context": "[CLIENT] (sentiment: positive, ...)\n[AGENT] ...",
    "conversation_stats": "Total messages: 5\nClient messages: 3\n...",
    "format_instructions": "The output should be formatted as a JSON instance..."
}
```

**Pourquoi ?** : Le prompt a besoin du contexte complet, pas juste le message actuel.

#### 2. `prompt`

**R√¥le** : Template de prompt qui injecte les variables.

**Template** (simplifi√©) :
```
Tu es un copilote intelligent expert en conversation temps r√©el.

## Contexte de la conversation :
{conversation_context}

## Dernier message analys√© :
Speaker: {speaker}
Sentiment: {sentiment}
Emotion: {emotion}
Texte: "{text}"

## Statistiques :
{conversation_stats}

## Format de r√©ponse :
{format_instructions}

Analyse ce message et fournis tes suggestions au format JSON.
```

**Output** : Prompt complet pr√™t pour le LLM.

#### 3. `llm`

**R√¥le** : Mod√®le de langage qui g√©n√®re la r√©ponse.

**Input** : Prompt complet (string)

**Output** : Texte JSON brut (string)

```json
{
  "questions": ["What specific aspect of pricing concerns you?", "..."],
  "signals_detected": ["pricing objection", "hesitation"],
  "recommended_direction": "Address concerns by emphasizing ROI."
}
```

#### 4. `output_parser`

**R√¥le** : Parse le JSON et valide avec Pydantic.

**Input** : String JSON

**Output** : `OutputSuggestion` (objet Pydantic valid√©)

```python
OutputSuggestion(
    questions=["What specific aspect...", "..."],
    signals_detected=["pricing objection", "hesitation"],
    recommended_direction="Address concerns by emphasizing ROI."
)
```

**Gestion d'erreur** : Si JSON invalide ou champs manquants ‚Üí `OutputParserException`

### Prompt system : Le cerveau de l'agent

**Fichier** : `app/agents/orchestrator.py` (hardcod√©, ligne 18-56)

**Probl√®me identifi√©** : Prompt int√©gr√© dans le code = difficile √† maintenir/versionner.

**Structure actuelle** :

```python
ORCHESTRATOR_SYSTEM_PROMPT = """
Tu es un copilote intelligent expert en conversation temps r√©el.

## Tes capacit√©s :
1. Analyse de sentiment et d'intention
2. D√©tection de signaux (objections, h√©sitations, int√©r√™ts)
3. Suggestions tactiques
4. Orientation strat√©gique

## Instructions :
- Analyse le contexte complet
- Identifie les signaux cl√©s
- Propose 2-3 questions pertinentes
- Donne une direction claire et actionnable

## Format de r√©ponse :
{format_instructions}

## Contexte de la conversation :
{conversation_context}

## Dernier message analys√© :
Speaker: {speaker}
Sentiment: {sentiment}
Emotion: {emotion}
Texte: "{text}"

## Statistiques de la conversation :
{conversation_stats}

Analyse ce dernier message dans le contexte global et fournis tes suggestions au format JSON.
"""
```

**Points forts** :
- Instructions claires et structur√©es
- Contexte riche (historique + statistiques)
- Format JSON impos√© pour coh√©rence

**Points d'am√©lioration** :
- Externaliser dans `agents/prompts.py` (voir section Am√©lioration)
- Ajouter des exemples (few-shot learning)
- Versioning pour A/B testing

---

## Comment ajouter de nouveaux agents

### Sc√©nario 1 : Agent de d√©tection de closing opportunities

**Objectif** : Agent sp√©cialis√© qui d√©tecte quand le client est pr√™t √† signer.

#### √âtape 1 : Cr√©er le fichier de l'agent

```python
# app/agents/closing_detector.py

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain_core.runnables import RunnableLambda
from pydantic.v1 import BaseModel, Field
from typing import List, Dict, Any
from app.memory.conversation_memory import ConversationMemory
from app.config.settings import settings

# Sch√©ma de sortie sp√©cifique √† ce agent
class ClosingSignal(BaseModel):
    """D√©tection d'opportunit√©s de closing."""
    
    closing_score: float = Field(
        description="Score de 0 √† 100 indiquant la probabilit√© de closing"
    )
    
    positive_signals: List[str] = Field(
        default_factory=list,
        description="Signaux positifs d√©tect√©s (accord, enthousiasme, etc.)"
    )
    
    blockers: List[str] = Field(
        default_factory=list,
        description="Obstacles restants (objections non r√©solues)"
    )
    
    recommended_action: str = Field(
        description="Action imm√©diate recommand√©e (ask for commitment, address blocker, nurture)"
    )

# Prompt system sp√©cialis√©
CLOSING_DETECTOR_PROMPT = """
Tu es un expert en d√©tection d'opportunit√©s de closing dans les conversations de vente.

Ton r√¥le est d'analyser la conversation et d√©terminer si le client est pr√™t √† prendre une d√©cision.

## Signaux positifs √† d√©tecter :
- Accord explicite sur la valeur
- Questions pratiques (timeline, onboarding, payment)
- R√©duction des objections
- Changement de ton (de sceptique √† positif)

## Blockers √† identifier :
- Objections non adress√©es
- Besoin d'approbation interne
- Budget non confirm√©
- Comparaison avec concurrents en cours

## Contexte de la conversation :
{conversation_context}

## Statistiques :
{conversation_stats}

## Dernier message :
Speaker: {speaker}
Texte: "{text}"

## Format de r√©ponse :
{format_instructions}

Analyse et fournis ton √©valuation au format JSON.
"""

def create_closing_detector_agent(memory: ConversationMemory):
    """Cr√©e l'agent de d√©tection de closing."""
    
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,  # Plus d√©terministe pour scoring
        max_tokens=300
    )
    
    output_parser = PydanticOutputParser(pydantic_object=ClosingSignal)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", CLOSING_DETECTOR_PROMPT)
    ])
    
    def prepare_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "text": inputs["text"],
            "speaker": inputs["speaker"],
            "conversation_context": memory.get_context(max_messages=30),
            "conversation_stats": format_stats(memory.get_conversation_summary()),
            "format_instructions": output_parser.get_format_instructions()
        }
    
    chain = (
        RunnableLambda(prepare_inputs)
        | prompt
        | llm
        | output_parser
    )
    
    return chain

def format_stats(stats: Dict[str, Any]) -> str:
    """Formate les stats pour le prompt."""
    if stats["total_messages"] == 0:
        return "D√©but de conversation"
    
    return f"""
    Total messages: {stats['total_messages']}
    Client: {stats['client_messages']}, Agent: {stats['agent_messages']}
    Sentiments: {dict(stats['sentiments'])}
    √âmotions: {dict(stats['emotions'])}
    """
```

#### √âtape 2 : Int√©grer dans le StreamHandler

**Option A : Ex√©cution parall√®le** (recommand√©)

```python
# app/handlers/stream_handler.py

from app.agents.closing_detector import create_closing_detector_agent, ClosingSignal

class StreamHandler:
    def __init__(self):
        self.memory = ConversationMemory(max_messages=settings.max_memory_messages)
        self.orchestrator_chain = create_orchestrator_agent(self.memory)
        self.closing_detector_chain = create_closing_detector_agent(self.memory)  # Nouveau
    
    async def process_message(self, input_msg: InputMessage) -> Dict[str, Any]:
        """Traite avec plusieurs agents en parall√®le."""
        
        # Ajouter √† la m√©moire
        self.memory.add_input_message(input_msg)
        
        # Invoquer les deux agents en parall√®le
        orchestrator_task = invoke_orchestrator(
            self.orchestrator_chain,
            input_msg.text,
            input_msg.speaker,
            input_msg.sentiment,
            input_msg.emotion
        )
        
        closing_detector_task = self.closing_detector_chain.ainvoke({
            "text": input_msg.text,
            "speaker": input_msg.speaker
        })
        
        # Attendre les deux r√©sultats
        orchestrator_result, closing_result = await asyncio.gather(
            orchestrator_task,
            closing_detector_task
        )
        
        # Combiner les r√©sultats
        return {
            "suggestions": orchestrator_result.dict(),
            "closing_signal": closing_result.dict()
        }
```

**Option B : Ex√©cution conditionnelle**

```python
async def process_message(self, input_msg: InputMessage) -> Dict[str, Any]:
    """Invoquer closing detector seulement si pertinent."""
    
    self.memory.add_input_message(input_msg)
    
    # Toujours invoquer l'orchestrator
    suggestion = await invoke_orchestrator(...)
    
    # Invoquer closing detector seulement si >10 messages
    closing_signal = None
    if len(self.memory.messages) > 10:
        closing_signal = await self.closing_detector_chain.ainvoke({
            "text": input_msg.text,
            "speaker": input_msg.speaker
        })
    
    return {
        "suggestions": suggestion.dict(),
        "closing_signal": closing_signal.dict() if closing_signal else None
    }
```

#### √âtape 3 : Mettre √† jour le sch√©ma de sortie

```python
# app/schemas/output.py

class CombinedOutput(BaseModel):
    """Sortie combin√©e de plusieurs agents."""
    
    suggestions: OutputSuggestionResponse  # Orchestrator
    closing_signal: Optional[Dict[str, Any]] = None  # Closing Detector
```

### Sc√©nario 2 : Agent de sentiment analysis avanc√©

**Objectif** : Agent d√©di√© √† l'analyse √©motionnelle fine-grained.

```python
# app/agents/sentiment_analyzer.py

class EmotionAnalysis(BaseModel):
    """Analyse √©motionnelle avanc√©e."""
    
    primary_emotion: str = Field(description="√âmotion principale")
    secondary_emotions: List[str] = Field(description="√âmotions secondaires")
    emotion_intensity: float = Field(description="Intensit√© de 0 √† 100")
    emotion_trend: str = Field(description="improving, stable, degrading")
    empathy_required: bool = Field(description="Si empathie n√©cessaire")

SENTIMENT_ANALYZER_PROMPT = """
Tu es un expert en analyse √©motionnelle des conversations.

Analyse le dernier message dans son contexte et d√©termine:
- L'√©motion principale et les √©motions secondaires
- L'intensit√© √©motionnelle
- La tendance (am√©lioration/d√©gradation)
- Si une r√©ponse empathique est n√©cessaire

Contexte r√©cent :
{recent_context}

Message actuel :
{text}

Format de sortie :
{format_instructions}
"""

def create_sentiment_analyzer(memory: ConversationMemory):
    """Cr√©e l'agent d'analyse de sentiment."""
    # ... similaire au closing detector
```

**Usage** : Enrichir les m√©tadonn√©es d'entr√©e ou fournir un contexte √©motionnel pour l'orchestrator.

---

## Syst√®me de tools

### Qu'est-ce qu'un tool LangChain ?

Un **tool** est une fonction que l'agent peut invoquer pour acc√©der √† des informations ou effectuer des actions externes.

**Exemples de tools** :
- Recherche dans une base de connaissances (Weaviate, Pinecone)
- Requ√™te API externe (CRM, base de donn√©es clients)
- Calculs complexes (scoring, pricing dynamique)
- Acc√®s √† des documents (PDF, wiki interne)

### Tool existant : Weaviate (RAG)

**Fichier** : `app/tools/weaviate_tool.py`

**√âtat actuel** : Pr√©par√© mais non activ√© (placeholder).

#### Anatomie d'un tool

```python
from langchain.tools import tool

@tool
def weaviate_search(query: str, limit: int = 5) -> List[Dict[str, Any]]:
    """
    Recherche dans la base de connaissances Weaviate (RAG).
    
    Args:
        query: Requ√™te de recherche s√©mantique
        limit: Nombre maximum de r√©sultats (d√©faut: 5)
    
    Returns:
        Liste de documents pertinents avec leur contenu et m√©tadonn√©es
    """
    # Impl√©mentation de la recherche
    # ...
    return results
```

**Composants cl√©s** :
1. **D√©corateur `@tool`** : Enregistre la fonction comme tool LangChain
2. **Docstring** : Le LLM lit ce texte pour comprendre quand l'utiliser
3. **Type hints** : Validation automatique des arguments
4. **Return type** : Structure de donn√©es retourn√©e

### Comment le LLM utilise un tool ?

#### Workflow avec tools (Function Calling)

```
1. User Input ‚Üí Prompt system avec liste des tools disponibles
2. LLM d√©cide : "Je dois utiliser le tool weaviate_search"
3. LLM g√©n√®re : { "tool": "weaviate_search", "args": {"query": "pricing structure", "limit": 3} }
4. LangChain ex√©cute weaviate_search("pricing structure", 3)
5. R√©sultats retourn√©s au LLM
6. LLM int√®gre les r√©sultats dans sa r√©ponse finale
7. Output final g√©n√©r√©
```

#### Exemple concret

**Sc√©nario** : Client demande "What are your pricing options?"

**Sans tool** :
```
LLM : "I'd be happy to discuss our pricing options. We offer several tiers..."
(R√©ponse g√©n√©rique, pas de d√©tails pr√©cis)
```

**Avec tool Weaviate** :
```
1. LLM d√©tecte le besoin d'information : "pricing"
2. LLM invoque : weaviate_search("pricing structure and options", limit=3)
3. Tool retourne :
   [
     {"content": "Enterprise tier: $5000/month for 100 users...", "source": "pricing_doc.pdf"},
     {"content": "Startup tier: $500/month for 10 users...", "source": "pricing_doc.pdf"},
     {"content": "Custom pricing available for 500+ users...", "source": "pricing_doc.pdf"}
   ]
4. LLM int√®gre dans sa r√©ponse :
   "Based on our pricing structure:
   - Startup tier: $500/month (up to 10 users)
   - Enterprise tier: $5000/month (up to 100 users)
   - Custom pricing for larger organizations
   
   Which size team are you working with?"
```

---

## Comment √©tendre ou remplacer les tools

### Extension 1 : Activer Weaviate

#### √âtape 1 : Configuration

```bash
# .env
WEAVIATE_URL=https://your-instance.weaviate.network
WEAVIATE_API_KEY=your_api_key_here
WEAVIATE_CLASS=ConversationKnowledge
```

#### √âtape 2 : D√©commenter l'impl√©mentation

```python
# app/tools/weaviate_tool.py

@tool
def weaviate_search(query: str, limit: int = 5) -> List[Dict[str, Any]]:
    """Recherche dans la base de connaissances Weaviate (RAG)."""
    
    try:
        import weaviate
        from weaviate.auth import AuthApiKey
        
        # Connexion √† Weaviate
        client = weaviate.Client(
            url=settings.weaviate_url,
            auth_client_secret=AuthApiKey(api_key=settings.weaviate_api_key)
        )
        
        # Recherche s√©mantique
        result = (
            client.query
            .get(settings.weaviate_class, ["content", "metadata"])
            .with_near_text({"concepts": [query]})
            .with_limit(limit)
            .do()
        )
        
        # Parser les r√©sultats
        documents = []
        if "data" in result and "Get" in result["data"]:
            class_data = result["data"]["Get"].get(settings.weaviate_class, [])
            for item in class_data:
                documents.append({
                    "content": item.get("content", ""),
                    "metadata": item.get("metadata", {})
                })
        
        return documents
        
    except Exception as e:
        logger.error(f"Erreur Weaviate: {e}")
        return [{"content": "Error occurred", "metadata": {"error": str(e)}}]
```

#### √âtape 3 : Binder le tool √† l'agent

```python
# app/agents/orchestrator.py

from app.tools.weaviate_tool import weaviate_search

def create_orchestrator_agent(memory: ConversationMemory):
    # ... code existant ...
    
    llm = ChatOpenAI(...)
    
    # Binder les tools au LLM
    llm_with_tools = llm.bind_tools([weaviate_search])
    
    # Remplacer 'llm' par 'llm_with_tools' dans la cha√Æne
    chain = (
        RunnableLambda(prepare_inputs)
        | prompt
        | llm_with_tools  # <-- Utiliser llm_with_tools
        | output_parser
    )
    
    return chain
```

#### √âtape 4 : Mettre √† jour le prompt

```python
ORCHESTRATOR_SYSTEM_PROMPT = """
Tu es un copilote intelligent expert en conversation temps r√©el.

## Outils disponibles :
- **weaviate_search** : Recherche dans la base de connaissances pour obtenir des informations pr√©cises sur nos produits, pricing, features, etc.

Utilise weaviate_search d√®s que tu as besoin d'informations factuelles que tu ne connais pas.

## Tes capacit√©s :
...
"""
```

### Extension 2 : Cr√©er un tool CRM

**Objectif** : R√©cup√©rer des informations sur le client depuis le CRM.

```python
# app/tools/crm_tool.py

from langchain.tools import tool
import httpx

@tool
async def get_customer_info(customer_id: str) -> Dict[str, Any]:
    """
    R√©cup√®re les informations d'un client depuis le CRM.
    
    Args:
        customer_id: ID unique du client
    
    Returns:
        Informations du client (nom, historique d'achats, tickets ouverts, etc.)
    """
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{settings.crm_api_url}/customers/{customer_id}",
                headers={"Authorization": f"Bearer {settings.crm_api_key}"},
                timeout=5.0
            )
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "name": data.get("name"),
                    "tier": data.get("subscription_tier"),
                    "account_value": data.get("lifetime_value"),
                    "open_tickets": data.get("open_tickets_count"),
                    "satisfaction_score": data.get("csat_score"),
                    "last_purchase_date": data.get("last_purchase_date")
                }
            else:
                return {"error": f"CRM returned status {response.status_code}"}
                
    except Exception as e:
        return {"error": str(e)}

@tool
def check_product_availability(product_name: str) -> Dict[str, Any]:
    """
    V√©rifie la disponibilit√© d'un produit.
    
    Args:
        product_name: Nom du produit
    
    Returns:
        Statut de disponibilit√© et informations
    """
    # Appel API vers syst√®me d'inventory
    # ...
    pass
```

**Usage** :

```python
# app/agents/orchestrator.py

from app.tools.crm_tool import get_customer_info, check_product_availability
from app.tools.weaviate_tool import weaviate_search

def create_orchestrator_agent(memory: ConversationMemory):
    llm = ChatOpenAI(...)
    
    # Binder plusieurs tools
    llm_with_tools = llm.bind_tools([
        weaviate_search,
        get_customer_info,
        check_product_availability
    ])
    
    # ... reste du code
```

**Prompt mis √† jour** :

```python
ORCHESTRATOR_SYSTEM_PROMPT = """
...

## Outils disponibles :
1. **weaviate_search(query, limit)** : Recherche dans la base de connaissances
2. **get_customer_info(customer_id)** : Informations CRM du client
3. **check_product_availability(product_name)** : Disponibilit√© produit

Utilise ces outils intelligemment pour fournir des suggestions pr√©cises et personnalis√©es.

Exemple :
- Si le client demande le pricing ‚Üí utilise weaviate_search("pricing structure")
- Si tu dois personnaliser ‚Üí utilise get_customer_info(customer_id)
- Si le client demande un produit sp√©cifique ‚Üí v√©rifie avec check_product_availability()

...
"""
```

### Extension 3 : Tool pour calculs dynamiques

**Objectif** : Calculer un pricing ou discount dynamique.

```python
# app/tools/pricing_tool.py

from langchain.tools import tool
from typing import Dict, Any

@tool
def calculate_custom_pricing(
    base_tier: str,
    num_users: int,
    contract_length_months: int,
    add_ons: List[str]
) -> Dict[str, Any]:
    """
    Calcule un pricing personnalis√© bas√© sur les besoins du client.
    
    Args:
        base_tier: Tier de base (starter, professional, enterprise)
        num_users: Nombre d'utilisateurs
        contract_length_months: Dur√©e du contrat en mois
        add_ons: Liste d'add-ons demand√©s
    
    Returns:
        Pricing d√©taill√© avec remises applicables
    """
    
    # Base pricing par tier
    base_prices = {
        "starter": 50,
        "professional": 200,
        "enterprise": 1000
    }
    
    base_price = base_prices.get(base_tier, 0)
    
    # Prix par utilisateur
    price_per_user = base_price * num_users
    
    # Remise volume
    volume_discount = 0
    if num_users >= 50:
        volume_discount = 0.15  # 15%
    elif num_users >= 20:
        volume_discount = 0.10  # 10%
    elif num_users >= 10:
        volume_discount = 0.05  # 5%
    
    # Remise dur√©e contrat
    contract_discount = 0
    if contract_length_months >= 24:
        contract_discount = 0.20  # 20%
    elif contract_length_months >= 12:
        contract_discount = 0.10  # 10%
    
    # Prix add-ons
    addon_prices = {
        "advanced_analytics": 500,
        "priority_support": 300,
        "custom_integration": 1000
    }
    
    addons_total = sum(addon_prices.get(addon, 0) for addon in add_ons)
    
    # Calcul final
    subtotal = price_per_user + addons_total
    total_discount = volume_discount + contract_discount
    final_price = subtotal * (1 - total_discount)
    
    return {
        "base_price_per_user": base_price,
        "total_users": num_users,
        "subtotal": subtotal,
        "volume_discount_percent": volume_discount * 100,
        "contract_discount_percent": contract_discount * 100,
        "total_discount_percent": total_discount * 100,
        "addons": add_ons,
        "addons_cost": addons_total,
        "final_monthly_price": round(final_price, 2),
        "annual_price": round(final_price * 12, 2)
    }
```

**Sc√©nario d'usage** :

Client : "What would it cost for 25 users on a professional plan for 2 years with advanced analytics?"

LLM :
1. D√©tecte besoin de pricing calculation
2. Invoque `calculate_custom_pricing("professional", 25, 24, ["advanced_analytics"])`
3. Tool retourne :
```json
{
  "final_monthly_price": 4950.00,
  "volume_discount_percent": 10,
  "contract_discount_percent": 20,
  "total_discount_percent": 30,
  "annual_price": 59400.00
}
```
4. LLM r√©pond : "For 25 users on the Professional plan with a 2-year commitment and advanced analytics, you would pay $4,950/month (or $59,400/year). This includes a 10% volume discount and 20% annual contract discount."

---

## Multi-agents orchestration

### Probl√®me : Un seul agent g√©n√©raliste vs plusieurs agents sp√©cialis√©s

**Approche actuelle** : Un agent orchestrator g√©n√©raliste qui fait tout.

**Limitation** :
- Difficile d'optimiser pour tous les cas d'usage
- Prompt trop long et complexe
- Performances sous-optimales sur t√¢ches sp√©cialis√©es

**Solution** : Architecture multi-agents avec coordination.

### Architecture propos√©e

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Meta-Orchestrator  ‚îÇ
                    ‚îÇ  (Coordinator)      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ              ‚îÇ              ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Tactical Agent‚îÇ  ‚îÇEmotion ‚îÇ  ‚îÇ  Closing  ‚îÇ
        ‚îÇ  (Questions)  ‚îÇ  ‚îÇAnalyzer‚îÇ  ‚îÇ Detector  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ              ‚îÇ              ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   Combiner  ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Impl√©mentation

#### Meta-Orchestrator

```python
# app/agents/meta_orchestrator.py

from typing import Dict, Any
from app.agents.orchestrator import create_orchestrator_agent
from app.agents.closing_detector import create_closing_detector_agent
from app.agents.sentiment_analyzer import create_sentiment_analyzer
from app.memory.conversation_memory import ConversationMemory

class MetaOrchestrator:
    """
    Coordonne plusieurs agents sp√©cialis√©s.
    
    D√©cide quels agents invoquer selon le contexte.
    """
    
    def __init__(self, memory: ConversationMemory):
        self.memory = memory
        
        # Cr√©er les agents sp√©cialis√©s
        self.tactical_agent = create_orchestrator_agent(memory)
        self.closing_detector = create_closing_detector_agent(memory)
        self.sentiment_analyzer = create_sentiment_analyzer(memory)
    
    async def process(
        self,
        text: str,
        speaker: str,
        sentiment: str,
        emotion: str
    ) -> Dict[str, Any]:
        """
        Coordonne les agents et combine les r√©sultats.
        """
        
        # D√©terminer quels agents invoquer
        agents_to_run = self._select_agents()
        
        # Ex√©cuter les agents en parall√®le
        tasks = []
        
        if "tactical" in agents_to_run:
            tasks.append(("tactical", self.tactical_agent.ainvoke({
                "text": text,
                "speaker": speaker,
                "sentiment": sentiment,
                "emotion": emotion
            })))
        
        if "closing" in agents_to_run:
            tasks.append(("closing", self.closing_detector.ainvoke({
                "text": text,
                "speaker": speaker
            })))
        
        if "sentiment" in agents_to_run:
            tasks.append(("sentiment", self.sentiment_analyzer.ainvoke({
                "text": text,
                "speaker": speaker
            })))
        
        # Attendre tous les r√©sultats
        results = {}
        for name, task in tasks:
            results[name] = await task
        
        # Combiner les r√©sultats
        return self._combine_results(results)
    
    def _select_agents(self) -> List[str]:
        """D√©cide quels agents invoquer selon le contexte."""
        
        agents = ["tactical"]  # Toujours invoquer l'agent tactique
        
        # Ajouter closing detector si >10 messages
        if len(self.memory.messages) > 10:
            agents.append("closing")
        
        # Ajouter sentiment analyzer si √©motion n√©gative r√©cente
        if self.memory.last_sentiment == "negative":
            agents.append("sentiment")
        
        return agents
    
    def _combine_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Combine les r√©sultats de plusieurs agents."""
        
        combined = {
            "suggestions": results.get("tactical", {}).dict(),
            "closing_signal": results.get("closing", {}).dict() if "closing" in results else None,
            "emotion_analysis": results.get("sentiment", {}).dict() if "sentiment" in results else None
        }
        
        # Enrichir les suggestions avec closing insights
        if combined["closing_signal"] and combined["closing_signal"]["closing_score"] > 70:
            combined["suggestions"]["recommended_direction"] = (
                f"[HIGH CLOSING OPPORTUNITY] {combined['suggestions']['recommended_direction']}"
            )
        
        return combined
```

#### Int√©gration dans StreamHandler

```python
# app/handlers/stream_handler.py

from app.agents.meta_orchestrator import MetaOrchestrator

class StreamHandler:
    def __init__(self):
        self.memory = ConversationMemory(max_messages=settings.max_memory_messages)
        self.meta_orchestrator = MetaOrchestrator(self.memory)  # Un seul point d'entr√©e
    
    async def process_message(self, input_msg: InputMessage) -> Dict[str, Any]:
        self.memory.add_input_message(input_msg)
        
        # Utiliser le meta-orchestrator
        result = await self.meta_orchestrator.process(
            text=input_msg.text,
            speaker=input_msg.speaker,
            sentiment=input_msg.sentiment,
            emotion=input_msg.emotion
        )
        
        return result
```

---

## Best practices

### 1. **S√©paration des prompts**

**√Ä faire** :
```python
# app/agents/prompts.py

ORCHESTRATOR_PROMPT = """..."""
CLOSING_DETECTOR_PROMPT = """..."""
SENTIMENT_ANALYZER_PROMPT = """..."""

# Versioning
ORCHESTRATOR_PROMPT_V2 = """..."""
```

**Usage** :
```python
from app.agents.prompts import ORCHESTRATOR_PROMPT

prompt = ChatPromptTemplate.from_messages([("system", ORCHESTRATOR_PROMPT)])
```

### 2. **Configuration des agents dans .env**

```bash
# Agent Configuration
ORCHESTRATOR_MODEL=gpt-4o-mini
ORCHESTRATOR_TEMPERATURE=0.7
ORCHESTRATOR_MAX_TOKENS=500

CLOSING_DETECTOR_MODEL=gpt-4o-mini
CLOSING_DETECTOR_TEMPERATURE=0.3  # Plus d√©terministe
CLOSING_DETECTOR_MAX_TOKENS=300
```

### 3. **Monitoring et logs**

```python
def create_orchestrator_agent(memory: ConversationMemory):
    llm = ChatOpenAI(...)
    
    # Ajouter des callbacks pour monitoring
    from langchain.callbacks import get_openai_callback
    
    with get_openai_callback() as cb:
        chain = ...
        logger.info(f"Agent cr√©√© - Tokens estim√©s: {cb.total_tokens}")
    
    return chain
```

### 4. **Tests unitaires**

```python
# tests/test_agents.py

import pytest
from app.agents.orchestrator import create_orchestrator_agent
from app.memory.conversation_memory import ConversationMemory

@pytest.mark.asyncio
async def test_orchestrator_detects_objection():
    memory = ConversationMemory()
    agent = create_orchestrator_agent(memory)
    
    result = await agent.ainvoke({
        "text": "This is too expensive for us",
        "speaker": "client",
        "sentiment": "negative",
        "emotion": "concerned"
    })
    
    assert "pricing" in " ".join(result.signals_detected).lower()
    assert len(result.questions) >= 2
```

---

**Prochain document** : `05-EXTENSIONS-ET-AMELIORATIONS.md`

