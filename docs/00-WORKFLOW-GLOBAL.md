# Workflow Global de l'Application - Vue d'ensemble

## ğŸ“‹ Introduction

Ce document explique le **workflow complet** de l'application Call Shadow AI Agent, de bout en bout, pour comprendre comment tout s'enchaÃ®ne depuis la rÃ©ception d'un message jusqu'Ã  la gÃ©nÃ©ration d'une suggestion.

---

## ğŸ”„ Vue d'ensemble du workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW COMPLET DE L'APPLICATION                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. CLIENT EXTERNE (Service Audio / Frontend)
   â”‚
   â”‚ Envoie message JSON via WebSocket ou REST
   â”‚ { text, speaker, sentiment, emotion }
   â”‚
   â–¼

2. API LAYER (FastAPI)
   â”‚
   â”œâ”€â–º WebSocket endpoint (/ws/conversation)
   â”‚   â”œâ”€ Accepte connexion
   â”‚   â”œâ”€ ReÃ§oit message JSON
   â”‚   â””â”€ Valide format avec Pydantic
   â”‚
   â”œâ”€â–º REST endpoint (/api/process)
   â”‚   â”œâ”€ ReÃ§oit POST request
   â”‚   â”œâ”€ Valide body avec Pydantic
   â”‚   â””â”€ Parse InputMessage
   â”‚
   â””â”€â–º Validation rÃ©ussie : InputMessage crÃ©Ã©
       â”‚
       â–¼

3. STREAM HANDLER (Pipeline de traitement)
   â”‚
   â”œâ”€â–º process_message(InputMessage)
   â”‚   â”‚
   â”‚   â”œâ”€ Ã‰tape 1 : Mise Ã  jour mÃ©moire
   â”‚   â”‚   â””â”€â–º ConversationMemory.add_input_message()
   â”‚   â”‚       â”œâ”€ Convertit en HumanMessage/AIMessage
   â”‚   â”‚       â”œâ”€ Ajoute Ã  self.messages (LangChain)
   â”‚   â”‚       â”œâ”€ Ajoute Ã  self.metadata_store (mÃ©tadonnÃ©es)
   â”‚   â”‚       â””â”€ GÃ¨re fenÃªtre glissante (max 50 messages)
   â”‚   â”‚
   â”‚   â””â”€ Ã‰tape 2 : Invocation orchestrator
   â”‚       â”‚
   â”‚       â–¼

4. ORCHESTRATOR AGENT (Analyse IA)
   â”‚
   â”œâ”€â–º invoke_orchestrator(chain, text, speaker, sentiment, emotion)
   â”‚   â”‚
   â”‚   â”œâ”€ Pipeline LCEL :
   â”‚   â”‚
   â”‚   â”‚   RunnableLambda(prepare_inputs)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€ RÃ©cupÃ¨re contexte conversationnel
   â”‚   â”‚   â”‚   â””â”€â–º memory.get_context(max_messages=20)
   â”‚   â”‚   â”‚       â””â”€ Formate : "[CLIENT] (sentiment, emotion): texte"
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€ Calcule statistiques
   â”‚   â”‚   â”‚   â””â”€â–º memory.get_conversation_summary()
   â”‚   â”‚   â”‚       â””â”€ Retourne : total_messages, sentiments, emotions
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€ Enrichit inputs avec contexte + stats
   â”‚   â”‚       â”‚
   â”‚   â”‚       â–¼
   â”‚   â”‚
   â”‚   â”‚   ChatPromptTemplate
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€ Injecte variables dans prompt system
   â”‚   â”‚   â”œâ”€ Contexte conversationnel complet
   â”‚   â”‚   â”œâ”€ Message actuel avec mÃ©tadonnÃ©es
   â”‚   â”‚   â””â”€ Instructions de format JSON
   â”‚   â”‚       â”‚
   â”‚   â”‚       â–¼
   â”‚   â”‚
   â”‚   â”‚   ChatOpenAI (GPT-4o-mini)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€ ReÃ§oit prompt complet
   â”‚   â”‚   â”œâ”€ Analyse le contexte + dernier message
   â”‚   â”‚   â”œâ”€ GÃ©nÃ¨re rÃ©ponse JSON structurÃ©e
   â”‚   â”‚   â””â”€ Retourne string JSON brut
   â”‚   â”‚       â”‚
   â”‚   â”‚       â–¼
   â”‚   â”‚
   â”‚   â”‚   PydanticOutputParser
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€ Parse le JSON brut
   â”‚   â”‚   â”œâ”€ Valide avec OutputSuggestion schema
   â”‚   â”‚   â”œâ”€ CrÃ©e objet Pydantic validÃ©
   â”‚   â”‚   â””â”€ Retourne OutputSuggestion
   â”‚   â”‚       â”‚
   â”‚   â”‚       â–¼
   â”‚
   â””â”€â–º OutputSuggestion retournÃ©
       {
         questions: ["Question 1", "Question 2"],
         signals_detected: ["signal1", "signal2"],
         recommended_direction: "Direction stratÃ©gique"
       }
       â”‚
       â–¼

5. RETOUR AU CLIENT
   â”‚
   â”œâ”€â–º WebSocket
   â”‚   â””â”€ websocket.send_json(suggestion.dict())
   â”‚       â””â”€ Client reÃ§oit JSON immÃ©diatement
   â”‚
   â”œâ”€â–º REST
   â”‚   â””â”€ return OutputSuggestionResponse.from_output_suggestion(suggestion)
   â”‚       â””â”€ Client reÃ§oit HTTP 200 avec JSON body
   â”‚
   â””â”€â–º Client affiche les suggestions Ã  l'utilisateur
```

---

## ğŸ“ ScÃ©nario dÃ©taillÃ© : Conversation de vente

Suivons une conversation complÃ¨te pour voir comment le systÃ¨me Ã©volue.

### Message 1 : Client entre en contact

#### Input

```json
{
  "text": "Hello, I'm interested in your product.",
  "speaker": "client",
  "sentiment": "positive",
  "emotion": "neutral"
}
```

#### Workflow dÃ©taillÃ©

**1. RÃ©ception (WebSocket)**
```python
# app/api/websocket.py : ligne 44-45

data = await websocket.receive_text()  # '{"text": "Hello...", ...}'
json_data = json.loads(data)           # Parse JSON
```

**2. Validation Pydantic**
```python
# app/api/websocket.py : ligne 53

input_msg = InputMessage(**json_data)
# âœ… Validation OK : tous les champs requis prÃ©sents
```

**3. Traitement StreamHandler**
```python
# app/api/websocket.py : ligne 56

suggestion = await stream_handler.process_message(input_msg)

# DÃ©tail interne (app/handlers/stream_handler.py : ligne 50-55)
self.memory.add_input_message(input_msg)  # Ajout Ã  la mÃ©moire
```

**4. Ã‰tat de la mÃ©moire**

```python
memory.messages = [
    HumanMessage(
        content="Hello, I'm interested in your product.",
        additional_kwargs={
            "speaker": "client",
            "sentiment": "positive",
            "emotion": "neutral"
        }
    )
]

memory.metadata_store = [
    {
        "speaker": "client",
        "sentiment": "positive",
        "emotion": "neutral",
        "text": "Hello, I'm interested in your product."
    }
]
```

**5. PrÃ©paration inputs orchestrator**

```python
# app/agents/orchestrator.py : ligne 91-104

def prepare_inputs(inputs):
    return {
        "text": "Hello, I'm interested in your product.",
        "speaker": "client",
        "sentiment": "positive",
        "emotion": "neutral",
        "conversation_context": "[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.",
        "conversation_stats": "Total messages: 1\nClient messages: 1\nAgent messages: 0\n...",
        "format_instructions": "The output should be formatted as a JSON instance..."
    }
```

**6. Prompt envoyÃ© Ã  GPT-4o-mini**

```
Tu es un copilote intelligent expert en conversation temps rÃ©el.

## Contexte de la conversation :
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.

## Dernier message analysÃ© :
Speaker: client
Sentiment: positive
Emotion: neutral
Texte: "Hello, I'm interested in your product."

## Statistiques de la conversation :
Total messages: 1
Client messages: 1
Agent messages: 0
Sentiments: {'positive': 1}
Ã‰motions: {'neutral': 1}

Analyse ce dernier message et fournis tes suggestions au format JSON.
```

**7. RÃ©ponse GPT-4o-mini (string JSON brut)**

```json
{
  "questions": [
    "What specific features are you most interested in?",
    "What challenges are you currently facing that our product could help solve?"
  ],
  "signals_detected": [
    "initial interest",
    "positive sentiment",
    "early stage conversation"
  ],
  "recommended_direction": "Build rapport and understand needs. Ask open-ended questions to discover pain points."
}
```

**8. Parsing avec PydanticOutputParser**

```python
# app/agents/orchestrator.py : ligne 110-111

result = await chain.ainvoke(inputs)
# result est maintenant un objet OutputSuggestion (Pydantic v1)

OutputSuggestion(
    questions=["What specific features...", "What challenges..."],
    signals_detected=["initial interest", "positive sentiment", "early stage"],
    recommended_direction="Build rapport and understand needs..."
)
```

**9. Retour au client (WebSocket)**

```python
# app/api/websocket.py : ligne 59-60

response = suggestion.dict()
await websocket.send_json(response)
```

**Client reÃ§oit** :
```json
{
  "questions": [
    "What specific features are you most interested in?",
    "What challenges are you currently facing that our product could help solve?"
  ],
  "signals_detected": [
    "initial interest",
    "positive sentiment",
    "early stage conversation"
  ],
  "recommended_direction": "Build rapport and understand needs. Ask open-ended questions to discover pain points."
}
```

---

### Message 2 : Agent rÃ©pond

#### Input

```json
{
  "text": "Great! Let me explain our key features.",
  "speaker": "agent",
  "sentiment": "positive",
  "emotion": "joy"
}
```

#### Workflow (identique, mais avec contexte enrichi)

**Ã‰tat mÃ©moire AVANT traitement** : 1 message (client)

**Traitement** : MÃªme pipeline que Message 1

**Ã‰tat mÃ©moire APRÃˆS traitement** : 2 messages (client + agent)

**Prompt envoyÃ© Ã  GPT-4o-mini** (contexte enrichi) :

```
## Contexte de la conversation :
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
[AGENT] (sentiment: positive, emotion: joy): Great! Let me explain our key features.

## Dernier message analysÃ© :
Speaker: agent
Sentiment: positive
Emotion: joy
Texte: "Great! Let me explain our key features."

## Statistiques :
Total messages: 2
Client messages: 1
Agent messages: 1
Sentiments: {'positive': 2}
Ã‰motions: {'neutral': 1, 'joy': 1}
```

**GPT-4o-mini analyse** :
- Le contexte montre un client intÃ©ressÃ©
- L'agent a rÃ©pondu positivement
- La conversation progresse bien
- Pas de signaux nÃ©gatifs

**Suggestions gÃ©nÃ©rÃ©es** :
```json
{
  "questions": [
    "Which features resonate most with your needs?",
    "How do you envision using this in your workflow?"
  ],
  "signals_detected": [
    "positive engagement",
    "agent actively presenting",
    "building value"
  ],
  "recommended_direction": "Continue feature presentation, watch for specific interests or objections."
}
```

---

### Message 3 : Client exprime une objection

#### Input

```json
{
  "text": "I'm concerned about the pricing. It seems expensive.",
  "speaker": "client",
  "sentiment": "negative",
  "emotion": "uncertain"
}
```

#### Changements notables dans le workflow

**Ã‰tat mÃ©moire** : 3 messages (client-agent-client)

**Prompt avec contexte complet** :

```
## Contexte de la conversation :
[CLIENT] (sentiment: positive, emotion: neutral): Hello, I'm interested in your product.
[AGENT] (sentiment: positive, emotion: joy): Great! Let me explain our key features.
[CLIENT] (sentiment: negative, emotion: uncertain): I'm concerned about the pricing. It seems expensive.

## Dernier message analysÃ© :
Speaker: client
Sentiment: negative      âš ï¸ Changement : positive â†’ negative
Emotion: uncertain       âš ï¸ Changement : neutral â†’ uncertain
Texte: "I'm concerned about the pricing. It seems expensive."

## Statistiques :
Total messages: 3
Client messages: 2
Agent messages: 1
Sentiments: {'positive': 2, 'negative': 1}  âš ï¸ Apparition de "negative"
Ã‰motions: {'neutral': 1, 'joy': 1, 'uncertain': 1}
```

**GPT-4o-mini dÃ©tecte** :
- Changement de sentiment (positif â†’ nÃ©gatif)
- Apparition d'incertitude
- Mot-clÃ© "pricing" + "expensive"
- Pattern : Objection aprÃ¨s prÃ©sentation

**Suggestions adaptÃ©es** :
```json
{
  "questions": [
    "What specific aspect of the pricing concerns you?",
    "Have you had a chance to compare with similar solutions?",
    "What budget range were you expecting?"
  ],
  "signals_detected": [
    "pricing objection",
    "value concern",
    "hesitation",
    "potential deal blocker"
  ],
  "recommended_direction": "Address pricing objection immediately. Focus on ROI and value proposition. Understand budget constraints before defending price."
}
```

---

## ğŸ” Workflow en production (avec amÃ©liorations)

Voici comment le workflow Ã©volue aprÃ¨s implÃ©mentation des spÃ©cifications prioritaires :

```
1. CLIENT EXTERNE
   â”‚
   â–¼

2. API LAYER avec SESSIONS
   â”‚
   â”œâ”€â–º WebSocket avec session_id
   â”‚   â”œâ”€ session_id fourni ? â†’ RÃ©cupÃ¨re handler existant
   â”‚   â””â”€ session_id absent ? â†’ CrÃ©e nouvelle session
   â”‚       â””â”€â–º SessionManager.create_session()
   â”‚
   â””â”€â–º Chaque client a son StreamHandler isolÃ©
       â”‚
       â–¼

3. STREAM HANDLER avec RETRY LOGIC
   â”‚
   â”œâ”€â–º process_message() avec gestion d'erreurs
   â”‚   â”‚
   â”‚   â”œâ”€ Try : Traitement normal
   â”‚   â”œâ”€ Catch RateLimitError : Retry avec backoff
   â”‚   â”œâ”€ Catch APITimeoutError : Retry max 3 fois
   â”‚   â””â”€ Catch OutputParsingException : Fallback suggestion
   â”‚       â”‚
   â”‚       â–¼

4. CONVERSATION MEMORY avec PERSISTENCE
   â”‚
   â”œâ”€â–º add_input_message()
   â”‚   â”œâ”€ Ajoute en RAM (rapide)
   â”‚   â””â”€ Background task : Sync avec Redis
   â”‚       â””â”€â–º Redis : key="session:abc:memory", TTL=24h
   â”‚
   â””â”€â–º Summarization automatique
       â”œâ”€ Si fenÃªtre >= 45 messages
       â””â”€â–º RÃ©sume 15 plus anciens, conserve synthÃ¨se + 35 rÃ©cents
           â”‚
           â–¼

5. ORCHESTRATOR avec CIRCUIT BREAKER
   â”‚
   â”œâ”€â–º invoke_orchestrator() protÃ©gÃ© par circuit breaker
   â”‚   â”‚
   â”‚   â”œâ”€ Ã‰tat CLOSED : RequÃªtes passent normalement
   â”‚   â”œâ”€ Ã‰tat OPEN : Fallback immÃ©diat (API down)
   â”‚   â””â”€ Ã‰tat HALF_OPEN : Test si API revenue
   â”‚       â”‚
   â”‚       â–¼

6. MULTI-AGENTS ORCHESTRATION
   â”‚
   â”œâ”€â–º MetaOrchestrator.process()
   â”‚   â”‚
   â”‚   â”œâ”€ SÃ©lection agents selon contexte
   â”‚   â”‚   â”œâ”€ Tactical Agent (toujours)
   â”‚   â”‚   â”œâ”€ Closing Detector (si >10 messages)
   â”‚   â”‚   â””â”€ Emotion Analyzer (si sentiment nÃ©gatif)
   â”‚   â”‚
   â”‚   â”œâ”€ ExÃ©cution parallÃ¨le (asyncio.gather)
   â”‚   â””â”€ Combinaison rÃ©sultats
   â”‚       â”‚
   â”‚       â–¼

7. RETOUR CLIENT avec ENRICHISSEMENT
   â”‚
   â””â”€â–º RÃ©ponse combinÃ©e :
       {
         "suggestions": { ... },           // Tactical Agent
         "closing_signal": { ... },        // Closing Detector (optionnel)
         "emotion_analysis": { ... }       // Emotion Analyzer (optionnel)
       }
```

---

## ğŸ¯ Points clÃ©s du workflow

### 1. **Flux de donnÃ©es unidirectionnel**

```
Input â†’ Validation â†’ MÃ©moire â†’ Agent â†’ Output
```

Pas de boucle, pas de retour en arriÃ¨re. Chaque Ã©tape enrichit les donnÃ©es.

### 2. **La mÃ©moire est le pivot central**

Tous les composants interagissent avec `ConversationMemory` :
- StreamHandler y ajoute les messages
- Orchestrator y lit le contexte
- SessionManager la gÃ¨re par session

### 3. **LCEL permet la composition dÃ©clarative**

```python
chain = prepare_inputs | prompt | llm | output_parser
```

Chaque Ã©tape est une transformation pure :
- `prepare_inputs` : Dict â†’ Dict enrichi
- `prompt` : Dict â†’ Prompt string
- `llm` : Prompt â†’ JSON string
- `output_parser` : JSON string â†’ Pydantic object

### 4. **Tout est asynchrone**

```python
async def process_message(...)
await handler.process_message(...)
await chain.ainvoke(...)
await websocket.send_json(...)
```

Permet la scalabilitÃ© et les opÃ©rations I/O non-bloquantes.

### 5. **Validation Ã  tous les niveaux**

- **Input** : Pydantic v2 valide le JSON entrant
- **LLM output** : PydanticOutputParser valide le JSON gÃ©nÃ©rÃ©
- **Configuration** : Pydantic Settings valide le .env

Si validation Ã©choue â†’ erreur claire, pas de corruption de donnÃ©es.

---

## ğŸ” Cas d'usage spÃ©cifiques

### Cas 1 : Service audio externe envoie transcriptions

**Workflow** :

```
Service Audio (Whisper/Deepgram)
    â”‚
    â”œâ”€ Transcrit audio en temps rÃ©el
    â”œâ”€ DÃ©tecte speaker (client/agent)
    â”œâ”€ Analyse sentiment/Ã©motion
    â”‚
    â–¼
WebSocket Client dans service audio
    â”‚
    â”œâ”€ Construit JSON : { text, speaker, sentiment, emotion }
    â”œâ”€ Envoie Ã  ws://lngc-service/ws/conversation?session_id=call-123
    â”‚
    â–¼
LNGC Service (ce projet)
    â”‚
    â”œâ”€ ReÃ§oit via WebSocket endpoint
    â”œâ”€ Traite avec pipeline normal (identique)
    â”œâ”€ GÃ©nÃ¨re suggestions
    â”‚
    â–¼
WebSocket Response
    â”‚
    â–¼
Service Audio reÃ§oit suggestions
    â”‚
    â”œâ”€ Affiche dans UI du commercial
    â””â”€ Ou envoie via TTS Ã  l'agent en direct
```

**ClÃ©** : Le workflow interne est **identique** que le client soit un frontend web, un service audio, ou un script Python. Tant que le JSON respecte `InputMessage`, Ã§a fonctionne.

### Cas 2 : Analyse batch post-appel

**Workflow** :

```
Fin d'appel
    â”‚
    â”œâ”€ Service extrait conversation complÃ¨te
    â”œâ”€ Construit liste de InputMessage
    â”‚
    â–¼
POST /api/analyze-batch
    {
      "messages": [msg1, msg2, ..., msgN],
      "conversation_id": "call-456"
    }
    â”‚
    â–¼
StreamHandler temporaire
    â”‚
    â”œâ”€ Pour chaque message :
    â”‚   â”œâ”€ add_input_message()
    â”‚   â””â”€ process_message()
    â”‚
    â”œâ”€ GÃ©nÃ¨re rapport de synthÃ¨se
    â”‚   â”œâ”€ Toutes les suggestions
    â”‚   â”œâ”€ Statistiques globales
    â”‚   â”œâ”€ Moments clÃ©s identifiÃ©s
    â”‚   â””â”€ Score overall
    â”‚
    â–¼
RÃ©ponse JSON complÃ¨te
    â”‚
    â–¼
Stockage dans analytics DB pour reporting
```

---

## ğŸ“Š Workflow visuel simplifiÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ Envoie message
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Layer                 â”‚
â”‚  - Validation Pydantic              â”‚
â”‚  - Gestion sessions (si activÃ©)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        StreamHandler                â”‚
â”‚  - Point d'entrÃ©e unique            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    â”‚                      â”‚
       â–¼                    â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conversation â”‚   â”‚  Orchestrator  â”‚   â”‚  Tools (RAG) â”‚
â”‚   Memory     â”‚â—„â”€â”€â”¤     Agent      â”‚â—„â”€â”€â”¤  (optionnel) â”‚
â”‚              â”‚   â”‚   (LCEL)       â”‚   â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  ChatOpenAI     â”‚
                   â”‚  (GPT-4o-mini)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Output Parser   â”‚
                   â”‚ (JSON â†’ Pydanticâ”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚OutputSuggestion â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Response      â”‚
                   â”‚   to Client     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â±ï¸ Latences typiques

| Ã‰tape | Latence | Notes |
|-------|---------|-------|
| RÃ©ception WebSocket | <5ms | Connexion persistante |
| Validation Pydantic | <1ms | TrÃ¨s rapide |
| Mise Ã  jour mÃ©moire | <1ms | OpÃ©ration en RAM |
| PrÃ©paration inputs | <5ms | Formatage texte |
| Appel OpenAI API | **300-800ms** | Goulot d'Ã©tranglement |
| Parsing output | <5ms | Validation JSON |
| Retour WebSocket | <5ms | Envoi JSON |
| **Total** | **~350-900ms** | DominÃ© par l'API OpenAI |

**Optimisations possibles** :
- Streaming token-par-token : PremiÃ¨re rÃ©ponse en ~100ms
- Cache pour suggestions rÃ©currentes : ~50ms
- ModÃ¨le local (Mistral) : ~200-400ms mais sans coÃ»t API

---

## ğŸ“ RÃ©sumÃ© exÃ©cutif

### Le workflow en 3 points

1. **RÃ©ception & Validation** : Message JSON â†’ Pydantic â†’ InputMessage
2. **Contexte & Analyse** : MÃ©moire + Message â†’ LCEL â†’ LLM â†’ Suggestions
3. **Retour** : OutputSuggestion â†’ JSON â†’ Client

### Les principes clÃ©s

- âœ… **Unidirectionnel** : Pas de boucles complexes
- âœ… **Stateless** : Chaque requÃªte est indÃ©pendante (mÃ©moire isolÃ©e par session)
- âœ… **Async** : ScalabilitÃ© et performance
- âœ… **ValidÃ©** : Pydantic Ã  l'entrÃ©e et la sortie
- âœ… **Modulaire** : Chaque composant est remplaÃ§able

### Comment tout s'enchaÃ®ne

```
Message â†’ MÃ©moire â†’ Contexte â†’ LLM â†’ Suggestions â†’ Client
         (stockage)  (enrichi)  (IA)  (validÃ©es)  (actionables)
```

Chaque message enrichit la mÃ©moire, qui enrichit le contexte, qui enrichit les suggestions, crÃ©ant une boucle de feedback intelligente sur toute la conversation.

---

**Pour aller plus loin** :
- DÃ©tails techniques â†’ [01-ARCHITECTURE-GENERALE.md](./01-ARCHITECTURE-GENERALE.md)
- Communication â†’ [02-WEBSOCKETS-ET-REST.md](./02-WEBSOCKETS-ET-REST.md)
- MÃ©moire â†’ [03-MEMOIRE-CONVERSATIONNELLE.md](./03-MEMOIRE-CONVERSATIONNELLE.md)
- Agents â†’ [04-AGENTS-ET-TOOLS.md](./04-AGENTS-ET-TOOLS.md)

